Walmart Recruiting - Store Sales Forecasting

პროექტის მიმოხილვა

ეს პროექტი წარმოადგენს Kaggle-ის კონკურსს „Walmart Recruiting - Store Sales Forecasting“, სადაც მიზანია Walmart-ის მაღაზიების ყოველკვირეული გაყიდვების პროგნოზირება სხვადასხვა მაღაზიისა და განყოფილებისთვის. პროექტის ფარგლებში გამოცდილია სხვადასხვა მოდელის არქიტექტურა Deep Learning Models - N-BEATS, Temporal Fusion Transformer, PatchTST, DLinear
Tree-Based Models - LightGBM, XGBoost Classical Statistical Time-Series Models - ARIMA, SARIMA, Prophet.

გამოყენებული მიდგომები

# 0. მონაცემთა წინასწარი დამუშავება (DataExploration)

მონაცემთა შეერთება: train.csv, features.csv, stores.csv ფაილები გაერთიანდა ერთ მონაცემთა ნაკრებად

საბოლოოდ მიიღებოდა მონაცემები 421570 სტრიქონითა და 16 სვეტით

სულ იყო 45 განსხვავებული მაღაზია და 81 დეპარტამენტი

მონაცემებში თარიღები საჭიროებდნენ კონვერტაციას: თარიღის ველები გარდაიქმნა datetime ფორმატში.

ასევე Weekly sales-ებში გვქონდა უარყოფითი მნიშვნელობები რომლებიც მონაცემების მხოლოდ 0.3% შეადგენდა ამიტომ მათი მოშორება ლოგიკური იყო

დავაკვირდით საშუალო თვიურ გაყიდვებს წლების მიხედვით. ინფორმაცია მოცემული იყო 2010 წლის მარტიდან 2012 წლის ოქტომბრის ჩათვლით და ყოველი თვისთვის გაყიდვები მერყეობდა 14k-20k

ამის შემდგომ ვნახეთ გაყიდვების მნიშვნელობების რაოდენობები და უმეტესად ისინი მერყეობდა 0-დან 50k-მდე

ასევე შევისწავლეთ გაყიდვების მაქსიმალური მნიშვნელობები და საშუალოები მაღაზიებისა და დეპარტამენტების მიხედვით და აღმოჩნდა , რომ იმ მაღაზიებსა და დეპარტამენტებს რომლებსაც ყველაზე
დიდი გაყიდვები უფიქსირდებოდათ საშუალოებში ყველაზე მაღალი არ ჰქონდა.

ასევე გაყიდვები დღესასწაულების კვირებში მატულობდა მაგრამ მთლიან მონაცემებთან შედარებიტ ეს მატება შესამჩნევი არ იყო

ხოლო რაც შეეხება მაღაზიის ტიპებს გაყიდვებში აქ შესამჩნევი განსხვავება იყო A ტიპის მაღაზიების გაყიდვები საგრძნობლად მაღალი იყო B და C ტიპის მაღაზიებთან შედარებით 

შემდგომ შევისწავლეთ კორელაცია Markdown-ებსა და გაყიდვებს შორის და აღმოჩნდა რომ ისინი დიდად კორელირებულები არ იყვნენ, იგივე რამ ხდებოდა feature-ების შემთხვევაში, ანუ მათ დიდი გავლენა არ ექნებოდათ prediction-ზე

და მაში კარგად დასარწმუნებლად გამოვიტანეთ Fuel Price, CPI , Unemployment , Temperature ეფექტების ნახაზებიც.





# 1. XGBoost 

DataPreprocessing 

დამატებულია დროის ფუნქციები: წელი, თვე, კვირა, დღე, სადღესასწაულო დღეების სიახლოვე (მაგ., ნოემბრის მადლიერების დღე, შობა).

Markdown-ის მონაცემების ნაკლოვანებების აღნიშვნა და შევსება (SimpleImputer-ით ან მედიანით).

Lag და Rolling Mean ფუნქციების დამატება გაყიდვების ისტორიის გათვალისწინებით (მაგ., Sales_Lag_1, Sales_Rolling_Mean_3).

დამატებულია სინუსოიდური ფუნქციები (sin_13, cos_13, sin_23, cos_23).

კატეგორიული ცვლადები: Type ცვლადი გარდაიქმნა რიცხვით ფორმატში (OrdinalEncoder-ით).

მოდელის არქიტექტურები

აღწერა: გამოყენებულია XGBRegressor ჰიპერპარამეტრების ოპტიმიზაციით Optuna-ს გამოყენებით. TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.1


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4300.16

# 2. LightGBM

DataPreprocessing

იგივე რაც xgboost-ის შემთხვევაში

მოდელის არქიტექტურები

აღწერა: გამოყენებულია LightGBM . TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.5


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4969.7372343221805

