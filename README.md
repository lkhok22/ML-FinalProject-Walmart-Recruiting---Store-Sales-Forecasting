# Walmart Recruiting - Store Sales Forecasting

პროექტის მიმოხილვა

ეს პროექტი წარმოადგენს Kaggle-ის კონკურსს „Walmart Recruiting - Store Sales Forecasting“, სადაც მიზანია Walmart-ის მაღაზიების ყოველკვირეული გაყიდვების პროგნოზირება სხვადასხვა მაღაზიისა და განყოფილებისთვის. პროექტის ფარგლებში გამოცდილია სხვადასხვა მოდელის არქიტექტურა Deep Learning Models - N-BEATS, Temporal Fusion Transformer, PatchTST, DLinear
Tree-Based Models - LightGBM, XGBoost Classical Statistical Time-Series Models - ARIMA, SARIMA, Prophet.

გამოყენებული მიდგომები

# 0. მონაცემთა წინასწარი დამუშავება (DataExploration)

მონაცემთა შეერთება: train.csv, features.csv, stores.csv ფაილები გაერთიანდა ერთ მონაცემთა ნაკრებად

საბოლოოდ მიიღებოდა მონაცემები 421570 სტრიქონითა და 16 სვეტით

სულ იყო 45 განსხვავებული მაღაზია და 81 დეპარტამენტი

მონაცემებში თარიღები საჭიროებდნენ კონვერტაციას: თარიღის ველები გარდაიქმნა datetime ფორმატში.

ასევე Weekly sales-ებში გვქონდა უარყოფითი მნიშვნელობები რომლებიც მონაცემების მხოლოდ 0.3% შეადგენდა ამიტომ მათი მოშორება ლოგიკური იყო

დავაკვირდით საშუალო თვიურ გაყიდვებს წლების მიხედვით. ინფორმაცია მოცემული იყო 2010 წლის მარტიდან 2012 წლის ოქტომბრის ჩათვლით და ყოველი თვისთვის გაყიდვები მერყეობდა 14k-20k

ამის შემდგომ ვნახეთ გაყიდვების მნიშვნელობების რაოდენობები და უმეტესად ისინი მერყეობდა 0-დან 50k-მდე

ასევე შევისწავლეთ გაყიდვების მაქსიმალური მნიშვნელობები და საშუალოები მაღაზიებისა და დეპარტამენტების მიხედვით და აღმოჩნდა , რომ იმ მაღაზიებსა და დეპარტამენტებს რომლებსაც ყველაზე
დიდი გაყიდვები უფიქსირდებოდათ საშუალოებში ყველაზე მაღალი არ ჰქონდა.

ასევე გაყიდვები დღესასწაულების კვირებში მატულობდა მაგრამ მთლიან მონაცემებთან შედარებიტ ეს მატება შესამჩნევი არ იყო

ხოლო რაც შეეხება მაღაზიის ტიპებს გაყიდვებში აქ შესამჩნევი განსხვავება იყო A ტიპის მაღაზიების გაყიდვები საგრძნობლად მაღალი იყო B და C ტიპის მაღაზიებთან შედარებით 

შემდგომ შევისწავლეთ კორელაცია Markdown-ებსა და გაყიდვებს შორის და აღმოჩნდა რომ ისინი დიდად კორელირებულები არ იყვნენ, იგივე რამ ხდებოდა feature-ების შემთხვევაში, ანუ მათ დიდი გავლენა არ ექნებოდათ prediction-ზე

და მაში კარგად დასარწმუნებლად გამოვიტანეთ Fuel Price, CPI , Unemployment , Temperature ეფექტების ნახაზებიც.





# 1. XGBoost 

DataPreprocessing 

დამატებულია დროის ფუნქციები: წელი, თვე, კვირა, დღე, სადღესასწაულო დღეების სიახლოვე (მაგ., ნოემბრის მადლიერების დღე, შობა).

Markdown-ის მონაცემების ნაკლოვანებების აღნიშვნა და შევსება (SimpleImputer-ით ან მედიანით).

Lag და Rolling Mean ფუნქციების დამატება გაყიდვების ისტორიის გათვალისწინებით (მაგ., Sales_Lag_1, Sales_Rolling_Mean_3).

დამატებულია სინუსოიდური ფუნქციები (sin_13, cos_13, sin_23, cos_23).

კატეგორიული ცვლადები: Type ცვლადი გარდაიქმნა რიცხვით ფორმატში (OrdinalEncoder-ით).

მოდელის არქიტექტურები

აღწერა: გამოყენებულია XGBRegressor ჰიპერპარამეტრების ოპტიმიზაციით Optuna-ს გამოყენებით. TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.1


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4300.16

# 2. LightGBM

DataPreprocessing

იგივე რაც xgboost-ის შემთხვევაში

მოდელის არქიტექტურები

აღწერა: გამოყენებულია LightGBM . TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.5


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4969.7372343221805


# SARIMAX 

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

მონაცემთა შეერთება: train.csv, features.csv, და stores.csv ფაილები გაერთიანდა ერთ მონაცემთა ნაკრებად, რის შედეგადაც მიღებული იქნა 421,570 სტრიქონი და 16 სვეტი, 45 მაღაზიისა და 81 დეპარტამენტის მონაცემებით.

თარიღის კონვერტაცია: თარიღის ველები გარდაიქმნა datetime ფორმატში.

უარყოფითი გაყიდვების მოშორება: უარყოფითი Weekly_Sales მნიშვნელობები, რომლებიც 0.3%-ს შეადგენდა, ამოღებულ იქნა.

დღესასწაულის წონა: შეიქმნა IsHolidayWeight სვეტი, სადაც დღესასწაულის კვირებს ენიჭებოდა წონა 5, ხოლო ჩვეულებრივ კვირებს — 1.

დღესასწაულის ფუნქციები: დამატებულია სპეციფიური ფუნქციები ძირითადი დღესასწაულებისთვის (SuperBowl, LaborDay, Thanksgiving, Christmas), მათ შორის კვირისა და მიახლოებული კვირების (2 კვირა ადრე/შემდეგ) ნიშნულები.

დროის ფუნქციები: დამატებულია WeekOfYear, Month, Year, Quarter (მეორე მიდგომისთვის), ასევე ციკლური ფუნქციები (Week_sin, Week_cos, Month_sin, Month_cos) სეზონური ნიმუშების აღსაწერად.

გამოტოვებული მნიშვნელობების მართვა:

Temperature, Fuel_Price, CPI, Unemployment შეივსო მაღაზიისა და თვის/მაღაზიის საშუალო მნიშვნელობებით.

MarkDown სვეტები შეივსო 0-ებით, რადგან გამოტოვებული მნიშვნელობები სავარაუდოდ ნიშნავს ფასდაკლების არარსებობას.


ურთიერთქმედების ფუნქციები (მეორე მიდგომა): დამატებულია Temp_Unemployment და Holiday_Markdown, ასევე Total_Markdown ფუნქცია, რომელიც აერთიანებს ყველა MarkDown სვეტს.


მოდელის არქიტექტურები:

პირველი მიდგომა (Fast SARIMAX):

აღწერა: გამოყენებულია SARIMAX მოდელი მარტივი პარამეტრებით (order=(1,0,0), seasonal_order=(0,0,0,52)) გამოთვლების დასაჩქარებლად. მოდელი გაწვრთნილია თითოეული მაღაზია-დეპარტამენტის კომბინაციისთვის (3331 კომბინაცია).

ოპტიმიზაცია:

გამოყენებულია simple_differencing=True სწრაფი განსხვავებისთვის.

maxiter=50 და method='lbfgs' გამოთვლების დასაჩქარებლად.


ჩავარდნის მართვა: თუ მონაცემები არასაკმარისი (<20) ან თითქმის მუდმივი იყო, გამოყენებული იქნა საშუალო გაყიდვების მნიშვნელობა.

შედეგები:


Validation WMAE: 5034.1327


დამუშავების დრო: 4.1 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0




მეორე მიდგომა (Improved SARIMAX):

აღწერა: გაუმჯობესებული SARIMAX მოდელი გარე რეგრესორებით (Temperature, Fuel_Price, CPI, Unemployment, Total_Markdown, Holiday_Markdown, SuperBowl_Week, LaborDay_Week, Thanksgiving_Week, Christmas_Week, Week_sin, Week_cos, Month_sin, Month_cos). გამოყენებულია უფრო რთული პარამეტრები (order=(1,1,1), seasonal_order=(1,1,1,52)).

ფუნქციების გაუმჯობესება:

დღესასწაულის ფუნქციები გაძლიერდა დამატებითი წონებით (1/(i+1)) 3 კვირის განმავლობაში დღესასწაულამდე/შემდეგ.

ოპტიმიზაცია:

maxiter=100 უკეთესი კონვერგენციისთვის.

გარე რეგრესორების NaN-ების მართვა ffill/bfill-ით.

ჩავარდნის მართვა: თუ მონაცემები არასაკმარისი (<30) ან თითქმის მუდმივი იყო, გამოყენებული იქნა საშუალო გაყიდვები.


შედეგები:

Validation WMAE: 2379.8436


დამუშავების დრო: 5.0 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0


ხარისხის შემოწმება:


მინიმალური პროგნოზი: 0.00


მაქსიმალური პროგნოზი: 182,527.96


საშუალო პროგნოზი: 15,982.75


უარყოფითი პროგნოზები: 0


ძირითადი გაუმჯობესებები

მეორე მიდგომის უპირატესობა: გარე რეგრესორების, ციკლური ფუნქციებისა და ურთიერთქმედების ფუნქციების დამატებამ მნიშვნელოვნად გააუმჯობესა WMAE (5034.1327-დან 2379.8436-მდე) და Public Score (7900-დან 4900-მდე).

სიჩქარე: მიუხედავად გაუმჯობესებული მოდელის სირთულისა, დამუშავების დრო მხოლოდ 0.9 წუთით გაიწელა (4.1-დან 5.0 წუთამდე).

სტაბილურობა: ორივე მიდგომაში 3331-ვე მაღაზია-დეპარტამენტის კომბინაციისთვის მოდელის მორგება წარმატებული იყო, ჩავარდნების გარეშე.




მესამე მიდგომა 

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

ძირითადი მახასიათებლები: იგივე, რაც მეორე მიდგომაში, დამატებით:

გაუმჯობესებული გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციების მართვა: გამოყენებულია დეპარტამენტის დონის საშუალო გაყიდვები დღესასწაულის/არადღესასწაულის მიხედვით, როგორც სარეზერვო (fallback) მნიშვნელობა, როდესაც მაღაზია-დეპარტამენტის კომბინაცია არ არსებობს სასწავლო მონაცემებში.

უარყოფითი პროგნოზების გამოსწორება: ყველა პროგნოზი გარდაიქმნა 0-ზე მეტ ან ტოლი მნიშვნელობებად.

მონაცემთა ნაკრები: 421,570 სტრიქონი, 45 მაღაზია, 81 დეპარტამენტი.


მოდელის არქიტექტურა

აღწერა: SARIMAX მოდელი გაუმჯობესებული გარე რეგრესორებით (Total_Markdown, Holiday_Markdown, SuperBowl_Week, Thanksgiving_Week, Christmas_Week, Week_sin, Week_cos). გამოყენებულია order=(1,0,2) და seasonal_order=(1,1,1,52) სტაბილურობისა და სიზუსტის გასაუმჯობესებლად.

ჩავარდნის მართვა:

თუ მონაცემები <30 ან თითქმის მუდმივი იყო, გამოყენებული იქნა დღესასწაულის/არადღესასწაულის საშუალო მნიშვნელობები.

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციებისთვის გამოყენებული იქნა დეპარტამენტის დონის საშუალო გაყიდვები.


ოპტიმიზაცია:

maxiter=100, method='lbfgs', optim_score='harvey' უკეთესი კონვერგენციისთვის.
გარე რეგრესორების NaN-ები შეივსო ffill/bfill-ით.


შედეგები:


Validation WMAE: 2494.3902


Public Score: 4600


დამუშავების დრო: 5.3 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0


გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციები: 11 (დაფარული დეპარტამენტის საშუალოებით)


ხარისხის შემოწმება:



მინიმალური პროგნოზი: 0.00


მაქსიმალური პროგნოზი: 263,476.20


საშუალო პროგნოზი: 15,986.92


უარყოფითი პროგნოზები: 0





ძირითადი გაუმჯობესებები

გაუმჯობესებული WMAE: 2379.8436-დან (მეორე მიდგომა) 2494.3902-მდე, მაგრამ Public Score გაუმჯობესდა 4900-დან 4600-მდე.

გამოტოვებული კომბინაციების მართვა: დეპარტამენტის დონის საშუალოებმა უზრუნველყო საიმედო სარეზერვო პროგნოზები 11 გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციისთვის.

სტაბილურობა: ყველა 3331 კომბინაციისთვის მოდელის მორგება წარმატებული იყო ჩავარდნების გარეშე.


მეოთხე მიდგომა (SARIMAX + Random Forest Hybrid)

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

ძირითადი მახასიათებლები:

მეხსიერების ოპტიმიზაცია: გამოყენებულია ოპტიმიზებული მონაცემთა ტიპები (int8, float32, int32) მეხსიერების მოხმარების შესამცირებლად.

მაღაზიისა და დეპარტამენტის სტატისტიკა: დამატებულია მაღაზიისა და დეპარტამენტის დონის საშუალო და სტანდარტული გადახრები (Store_Sales_Mean, Store_Sales_Std, Dept_Sales_Mean, Dept_Sales_Std).

მაღაზიის ტიპის dummy ცვლადები: Type_A, Type_B, Type_C გარდაიქმნა int8-ად.

დაგვიანებული (Lagged) ფუნქციები: დამატებულია Weekly_Sales-ის 1-კვირიანი დაგვიანებული მნიშვნელობები (Lagged_Sales).

მოძრავი საშუალო (Rolling Mean): 4-კვირიანი მოძრავი საშუალო Weekly_Sales-ისთვის.

გამოტოვებული მნიშვნელობების მართვა:

Temperature, Fuel_Price, CPI, Unemployment შეივსო მაღაზიისა და თვის საშუალოებით.

MarkDown სვეტები შეივსო 0-ებით.

მონაცემთა ნაკრები: იგივე 421,570 სტრიქონი, 45 მაღაზია, 81 დეპარტამენტი.



მოდელის არქიტექტურა

აღწერა: ჰიბრიდული მიდგომა, რომელიც აერთიანებს SARIMAX-სა და RandomForestRegressor-ს:

SARIMAX: გამოყენებულია მაღალი ვარიაციის (>1000) და საკმარისი მონაცემების (≥50) მქონე სერიებისთვის, order=(1,0,1), seasonal_order=(0,1,1,52). 

Random Forest: გამოყენებულია, როგორც სარეზერვო, როდესაც SARIMAX-ის WMAE > 10,000 ან მონაცემები არ არის საკმარისი SARIMAX-ისთვის. მახასიათებლები: Total_Markdown, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday, WeekOfYear, Month, 

Size, Type_A, Type_B, Type_C, Week_sin, Week_cos, Month_sin, Month_cos, Store_Sales_Mean, Dept_Sales_Mean, Lagged_Sales, დაგვიანებული და მოძრავი საშუალო ფუნქციები.

სტატისტიკური სარეზერვო: გამოყენებულია, როდესაც ორივე მოდელი ვერ მუშაობს, დღესასწაულის/არადღესასწაულის საშუალოებით.


ჩავარდნის მართვა:

თუ SARIMAX ჩავარდა ან WMAE > 10,000, გამოყენებული იქნა Random Forest.

თუ Random Forest-ისთვის მონაცემები <8, გამოყენებული იქნა სტატისტიკური საშუალო.

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციებისთვის: 0.6 * დეპარტამენტის საშუალო + 0.4 * მაღაზიის საშუალო.



ოპტიმიზაცია:

SARIMAX: maxiter=50, method='lbfgs', gtol=1e-6.

Random Forest: n_estimators=50, max_depth=6, min_samples_split=5, min_samples_leaf=3, max_features='sqrt'.

მეხსიერების მართვა: პარტიული (batch) დამუშავება (500 კომბინაცია თითო პარტიაში) და gc.collect() მეხსიერების გასაწმენდად.


შედეგები:


Validation WMAE: არ არის მოცემული (სავარაუდოდ, შედარებადია მესამე მიდგომასთან).

დამუშავების დრო: 5.3 წუთი (შედარებადი მესამე მიდგომასთან).

მოდელის განაწილება:

SARIMAX: გამოყენებული მაღალი ვარიაციის სერიებისთვის.

Random Forest: გამოყენებული SARIMAX-ის ჩავარდნის ან სუსტი შედეგის შემთხვევაში.

სტატისტიკური: გამოყენებული მცირე მონაცემების ან მარტივი სერიებისთვის.


ხარისხის შემოწმება:

მინიმალური პროგნოზი: 0.00

მაქსიმალური პროგნოზი: მაღალი (ზუსტი მნიშვნელობა არ არის მოცემული).

საშუალო პროგნოზი: 15,986.92 (მსგავსი მესამე მიდგომისა).

უარყოფითი პროგნოზები: 0

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციები: გარკვეული რაოდენობა (ზუსტი რიცხვი არ არის მოცემული), დაფარული დეპარტამენტისა და მაღაზიის საშუალოებით.



ძირითადი გაუმჯობესებები

ჰიბრიდული მიდგომა: SARIMAX-ისა და Random Forest-ის კომბინაციამ უზრუნველყო მოქნილობა, სადაც SARIMAX გამოიყენებოდა ძლიერი სეზონური ნიმუშებისთვის, ხოლო Random Forest — უფრო რთული, არაწრფივი ურთიერთქმედებებისთვის.

მეხსიერების ოპტიმიზაცია: მონაცემთა ტიპების შემცირებამ და პარტიულმა დამუშავებამ გააუმჯობესა ეფექტურობა.

გაძლიერებული ფუნქციები: დაგვიანებული და მოძრავი საშუალო ფუნქციებმა გააუმჯობესა Random Forest-ის მუშაობა.

ჩავარდნის მართვა: სამსაფეხურიანი სარეზერვო სისტემა (SARIMAX → Random Forest → სტატისტიკური) უზრუნველყოფდა ყველა შემთხვევის დაფარვას.




# Prophet


მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

მონაცემთა შეერთება:
train.csv, test.csv, features.csv, და stores.csv გაერთიანდა ერთ მონაცემთა ნაკრებად (combined_df) Store და Date სვეტებზე left join-ის გამოყენებით.

დამატებულია Set სვეტი (train ან test) მონაცემთა წყაროს განსასხვავებლად.

მონაცემთა ნაკრები შეიცავს 421,570 სტრიქონს, 45 მაღაზიას და 81 დეპარტამენტს.

თარიღის კონვერტაცია:

Date სვეტი გარდაიქმნა datetime ფორმატში.


Prophet-ისთვის მომზადება:

Date გადაკეთდა ds და Weekly_Sales გადაკეთდა y Prophet-ის ფორმატისთვის.

NaN მნიშვნელობები Weekly_Sales-ში შეივსო 0-ებით, რადგან Prophet არ იღებს NaN-ებს.

მონაცემთა დახარისხება:

მონაცემები დახარისხდა Store, Dept, და Date-ის მიხედვით.

გამოტოვებული მნიშვნელობები:

features.csv-ისა და stores.csv-ის გაერთიანებისას გამოტოვებული მნიშვნელობები არ იყო სპეციფიურად დამუშავებული, გარდა Weekly_Sales-ისა test.csv-ში (შეივსო NaN-ებით, როგორც placeholder).


ფუნქციები:

არ გამოყენებულა გარე რეგრესორები ან დამატებითი ფუნქციები (მაგ., Temperature, CPI, MarkDown), რადგან Prophet-ის ძირითადი მოდელი ფოკუსირებულია მხოლოდ ds და y სვეტებზე.



მოდელის არქიტექტურა

აღწერა:
გამოყენებულია Prophet მოდელი თითოეული მაღაზია-დეპარტამენტის კომბინაციისთვის (3331 კომბინაცია).
Prophet-ის პარამეტრები:

yearly_seasonality=True (ჩართულია წლიური სეზონურობა).

ნაგულისხმევი weekly_seasonality და daily_seasonality გამორთულია, რადგან მონაცემები ყოველკვირეულია.

მოდელი გაწვრთნილია train მონაცემებზე (ds, y) და პროგნოზი გაკეთდა test მონაცემების თარიღებისთვის.


ჩავარდნის მართვა:

თუ მაღაზია-დეპარტამენტის კომბინაციას ჰქონდა <2 მონაცემთა წერტილი, ის გამოტოვებული იქნა.
გამოტოვებული კომბინაციებისთვის (test-ში, რომლებიც არ იყო train-ში), პროგნოზები შეივსო 0-ებით sample_submission-ის გამოყენებით.


ოპტიმიზაცია:

Prophet-ის ნაგულისხმევი ოპტიმიზაცია გამოყენებულია (method='lbfgs', iter=10000).

უარყოფითი პროგნოზები გარდაიქმნა 0-ზე (clip(lower=0)).

პროგნოზები დამრგვალდა 2 ათწილადამდე.


ვალიდაცია:


გამოყენებულია ბოლო 10 კვირა train მონაცემებიდან ვალიდაციისთვის (Store 1, Dept 1).


MAE: 1560.9705


RMSE: 2011.2182


შედეგები:


Validation WMAE: არ არის მოცემული (MAE და RMSE გამოთვლილია მხოლოდ Store 1, Dept 1-ისთვის).


Public Score: არ არის მოცემული.


დამუშავების დრო: არ არის მოცემული, მაგრამ Prophet-ის მოდელი ზოგადად უფრო ნელია, ვიდრე SARIMAX, მრავალი კომბინაციის გამო.



ძირითადი გაუმჯობესებები

Prophet-ის გამოყენება:

Prophet-ის სიძლიერეა მისი მარტივი გამოყენება და სეზონური ნიმუშების (განსაკუთრებით წლიური) ავტომატური ამოცნობა, რაც ამცირებს ფუნქციების ხელით შექმნის საჭიროებას.

თუმცა, ამ მიდგომაში არ გამოყენებულა გარე რეგრესორები (Temperature, CPI, MarkDown), რაც შეიძლება შეზღუდავდეს სიზუსტეს.


შეზღუდვები

გარე რეგრესორების არარსებობა: Prophet-ის მოდელმა არ გამოიყენა features.csv-ის ცვლადები (მაგ., Temperature, CPI, MarkDown), რაც შეიძლება ზღუდავდეს მის სიზუსტეს SARIMAX-ის მიდგომებთან შედარებით.
ვალიდაციის შეზღუდვა: MAE და RMSE გამოთვლილია მხოლოდ ერთი მაღაზია-დეპარტამენტისთვის (Store 1, Dept 1), რაც არ წარმოადგენს ყოვლისმომცველ შეფასებას.
გამოტოვებული მნიშვნელობები: გამოტოვებული კომბინაციებისთვის 0-ის გამოყენება ნაკლებად ზუსტია, ვიდრე მესამე/მეოთხე მიდგომების საშუალოებზე დაფუძნებული მიდგომა.
სიჩქარე: Prophet-ის მრავალი მოდელის გაწვრთნა (3331 კომბინაციისთვის) შეიძლება უფრო ნელი იყოს, ვიდრე SARIMAX, თუმცა ზუსტი დრო არ არის მოცემული.

შედარება წინა მიდგომებთან

სიზუსტე: Prophet-ის MAE (1560.9705) Store 1, Dept 1-ისთვის უკეთესია, ვიდრე SARIMAX-ის Validation WMAE (2379.8436-2494.3902), მაგრამ ეს არ არის ყოვლისმომცველი, რადგან ვალიდაცია შესრულდა მხოლოდ ერთ კომბინაციაზე.
Public Score: არ არის მოცემული, მაგრამ მესამე/მეოთხე მიდგომების 4600-თან შედარებით, Prophet-ის სიზუსტე შეიძლება იყოს ნაკლები გარე რეგრესორების გამოყენების გარეშე.
ფუნქციები: Prophet-ის მარტივი მიდგომა (მხოლოდ ds, y) ნაკლებად მდიდარია, ვიდრე SARIMAX-ისა და Random Forest-ის ფუნქციები (მაგ., Total_Markdown, Lagged_Sales, Week_sin).
გამოთვლითი ეფექტურობა: Prophet-ის მრავალი მოდელის გაწვრთნა შეიძლება უფრო მეტ დროს მოითხოვდეს, განსაკუთრებით 3331 კომბინაციისთვის, თუმცა ოპტიმიზაციის სპეციფიური ზომები (მაგ., პარტიული დამუშავება) არ გამოყენებულა.

დასკვნა
Prophet-ის მიდგომა გთავაზობთ მარტივ, ავტომატიზებულ გადაწყვეტას სეზონური ნიმუშებისთვის, მაგრამ მისი ეფექტურობა შეიძლება შეიზღუდოს გარე ცვლადების გამოყენების არარსებობით და გამოტოვებული კომბინაციებისთვის 0-ის გამოყენებით. SARIMAX-ისა და Random Forest-ის ჰიბრიდული მიდგომები (მესამე/მეოთხე) უფრო ზუსტია, რადგან ისინი იყენებენ მდიდარ ფუნქციებს და უკეთეს სარეზერვო სტრატეგიებს.





# DLinear 

---------------------approache 1---------------------

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემთა ნაკრები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. მონაცემები გაერთიანდა Store და Date ცვლადებზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-MarkDown5, CPI, Unemployment, Temperature, Fuel_Price, Size შეივსო 0-ებით ან საშუალო მნიშვნელობებით.



IsHoliday გარდაიქმნა 0/1-ად, Type გარდაიქმნა რიცხვებად (A=0, B=1, C=2).



გამოყენებულია StandardScaler Weekly_Sales-ისა და თვისებების ნორმალიზაციისთვის, clipping [-1e5, 1e5].



დროის სერიების შექმნა: მონაცემები გაიყო მაღაზია-განყოფილების წყვილებად (Store, Dept). შეიქმნა უწყვეტი ყოველკვირეული მონაცემები pd.date_range-ის გამოყენებით, ხარვეზები შეივსო ffill-ით ან 0-ებით.



თვისებები: 12 ეგზოგენური თვისება (Temperature, Fuel_Price, CPI, Unemployment, MarkDown1-5, Size, Type, IsHoliday).



მონაცემთა ნაკრები:





train: 251,133 ნიმუში



validation: 316,241 ნიმუში

მოდელის არქიტექტურა





DLinear მოდელი:





Trend: ერთი nn.Linear(seq_len, pred_len) ფენა.



Seasonal: ერთი nn.Linear(seq_len, pred_len) ფენა.



Exogenous: ერთი nn.Linear(seq_len * n_features, pred_len) ფენა.



გამომავალი: trend + seasonal + exogenous.



პარამეტრები:





seq_len=36, pred_len=6, n_features=12.



Adam ოპტიმიზატორი lr=0.001.



ზარალი: MSE + WMAE (Weighted Mean Absolute Error, წონები: 4 დღესასწაულებისთვის, 1 სხვა დღეებისთვის).



ტრენინგი:





20 ეპოქა, batch size=32.



გრადიენტის clipping (max_norm=1.0).



WandB მონიტორინგი.

შედეგები





საბოლოო მეტრიკები (ეპოქა 20):





Train MSE: 0.0956, Train WMAE: 0.2780



Val MSE: 0.1057, Val WMAE: 0.2752



Public Score: 6098



ანალიზი:





Train WMAE სტაბილური (~0.277-0.289), Val WMAE მერყეობდა (0.2376-0.2935).



მარტივი არქიტექტურა შეიძლება ზღუდავდეს რთული ნიმუშების აღქმას.



მაღალი Val WMAE ეპოქა 6-ზე (0.2935) მიუთითებს გადაჭარბებულ მორგებაზე ან მონაცემთა ხარვეზებზე.



---------------------approache 2---------------------

მონაცემთა წინასწარი დამუშავება





განსხვავებები მიდგომა 1-ისგან:





დაემატა ოთხი სადღესასწაულო თვისება: SuperBowl, LaborDay, Thanksgiving, Christmas (1 თუ თარიღი ემთხვევა, 0 სხვა შემთხვევაში).



თვისებების რაოდენობა გაიზარდა 12-დან 16-მდე.



სხვა წინასწარი დამუშავება იდენტურია.



მონაცემთა ნაკრები:





სასწავლო: 251,133 ნიმუში



ვალიდაციის: 316,241 ნიმუში

მოდელის არქიტექტურა





DLinear მოდელი:





Trend: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით და dropout (0.1).



Seasonal: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით და dropout (0.1).



Exogenous: სამფენიანი MLP (seq_len * n_features -> 512 -> 256 -> pred_len) ReLU-ით და dropout (0.1).



გამომავალი: trend + seasonal + exogenous.



პარამეტრები:





seq_len=36, pred_len=6, n_features=16.



Adam ოპტიმიზატორი lr=0.0001.



ზარალი: MSE + 2 * WMAE.



Early stopping (patience=5) Val WMAE-ზე.



გრადიენტის clipping (max_norm=1.0).



ტრენინგი:





20 ეპოქა, batch size=32.



WandB მონიტორინგი unscaled WMAE-ით.

შედეგები





საბოლოო მეტრიკები (ეპოქა 20):





Train MSE: 0.0753, Train WMAE: 0.2026, Train WMAE Unscaled: 4148.68



Val MSE: 0.0585, Val WMAE: 0.1565, Val WMAE Unscaled: 3203.88



Public Score: 4906



ანალიზი:





Val WMAE გაუმჯობესდა (0.1565 vs 0.2752).



Unscaled WMAE (Train: 4148.68, Val: 3203.88) ზუსტი პროგნოზები.



ღრმა MLP და სადღესასწაულო თვისებები აუმჯობესებენ სეზონური ნიმუშების აღქმას.



Early stopping თავიდან აიცილებს გადაჭარბებულ მორგებას (საუკეთესო Val WMAE: 0.1560 ეპოქა 18).



---------------------  approache 3  ---------------------

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები Google Drive-დან. გაერთიანდა Store და Date-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5, CPI, Unemployment, Temperature, Fuel_Price, Size 0-ებით ან საშუალო მნიშვნელობებით.



IsHoliday გარდაიქმნა 0/1-ად, Type (A=0, B=1, C=2).



დაემატა სადღესასწაულო თვისებები: SuperBowl, LaborDay, Thanksgiving, Christmas.



დაემატა დროის თვისებები: WeekOfYear, Month, Year.



დაემატა სიახლოვის თვისებები: SuperBowl_Before/After, LaborDay_Before/After (±2 კვირა).



დაემატა lagged გაყიდვები: Lag1, Lag2, Lag4.



StandardScaler 26 თვისებაზე, clipping [-1e5, 1e5].



დროის სერიების შექმნა: გაიყო მაღაზია-განყოფილებებად, შეიქმნა უწყვეტი მონაცემები pd.date_range-ით.



თვისებები: 26 ეგზოგენური თვისება (Temperature, Fuel_Price, CPI, Unemployment, MarkDown1-5, Size, Type, IsHoliday, SuperBowl, LaborDay, Thanksgiving, Christmas, WeekOfYear, Month, Year, Lag1, Lag2, Lag4, SuperBowl_Before/After, LaborDay_Before/After).



მონაცემთა ნაკრები:





სასწავლო: 251,133 ნიმუში



ვალიდაციის: 316,241 ნიმუში

მოდელის არქიტექტურა





გაძლიერებული DLinear მოდელი:





Trend: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით, dropout (0.2).



Seasonal: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით, dropout (0.2).



Exogenous: Attention ფენა (feature_dim=26, attention_dim=128), შემდეგ სამფენიანი MLP (seq_len * n_features -> 512 -> 256 -> pred_len) ReLU-ით, dropout (0.2).



Holiday-Specific: სამფენიანი MLP (seq_len * 5 -> 256 -> pred_len) დღესასწაულებისთვის (IsHoliday, SuperBowl, LaborDay, Thanksgiving, Christmas).



Trend Decomposition: nn.AvgPool1d (kernel_size=7) ტრენდის გამოყოფისთვის.



კომბინაცია: nn.Linear(pred_len * 4, pred_len) ყველა კომპონენტის გაერთიანებისთვის.



პარამეტრები:





seq_len=36, pred_len=6, n_features=26, dropout=0.2, kernel_size=7.



Adam ოპტიმიზატორი lr=0.0001, weight_decay=1e-5.



ზარალი: MSE + 3 * WMAE.



ReduceLROnPlateau (factor=0.5, patience=3).



Early stopping (patience=10) Val WMAE-ზე.



გრადიენტის clipping (max_norm=1.0).



ტრენინგი:





50 ეპოქა, batch size=32.



WandB მონიტორინგი unscaled WMAE-ით.

შედეგები





საბოლოო მეტრიკები (ეპოქა 50):





Train MSE: 0.0476, Train WMAE: 0.1100, Train WMAE Unscaled: 2252.39



Val MSE: 0.0400, Val WMAE: 0.0835, Val WMAE Unscaled: 1710.73



Public Score: არ არის მოწოდებული.



ანალიზი:





მნიშვნელოვანი გაუმჯობესება Val WMAE (0.0835 vs 0.1565) და unscaled WMAE (1710.73 vs 3203.88).



Attention და სადღესასწაულო ფენა აუმჯობესებს თვისებების ურთიერთქმედებას.



Early stopping არ გააქტიურდა, საუკეთესო Val WMAE: 0.0833 ეპოქა 46.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





იგივე წინასწარი დამუშავება (26 თვისება, სკალირება, lagged გაყიდვები).



შეიქმნა თანმიმდევრობები, გამოყენებულია სასწავლო მონაცემები lagged-ისთვის.



პროგნოზი:





ჩაიტვირთა საუკეთესო მოდელი (enhanced_dlinear_model_best_v3.pth).



გენერირებული პროგნოზები პირველი კვირისთვის (pred_len=6).



განხორციელდა inverse transform scaler_sales-ით.



პროგნოზები შეზღუდულია არაუარყოფით მნიშვნელობებზე.



----------//შედარება მიდგომების//----------

ძირითადი განსხვავებები





features:





მიდგომა 1: 12 features.



მიდგომა 2: 16 features.



მიდგომა 3: 26 features (WeekOfYear, Month, Year, Lag1, Lag2, Lag4, SuperBowl_Before/After, LaborDay_Before/After).



არქიტექტურა:





მიდგომა 1: ხაზოვანი ფენები.



მიდგომა 2: სამფენიანი MLP ReLU-ით, dropout (0.1).



მიდგომა 3: სამფენიანი MLP, attention, სადღესასწაულო ფენა, ტრენდის გამოყოფა.



სწავლის სიჩქარე:





მიდგომა 1: lr=0.001.



მიდგომა 2: lr=0.0001.



მიდგომა 3: lr=0.0001 ReduceLROnPlateau-ით.



error:





მიდგომა 1: MSE + WMAE.



მიდგომა 2: MSE + 2 * WMAE.



მიდგომა 3: MSE + 3 * WMAE.



დამატებითი მექანიზმები:





მიდგომა 3: attention, სადღესასწაულო MLP, ტრენდის გამოყოფა.



ტრენინგის ხანგრძლივობა:





მიდგომა 1 & 2: 20 ეპოქა.



მიდგომა 3: 50 ეპოქა early stopping-ით (patience=10).



მეტრიკები:





მიდგომა 3: საუკეთესო Val WMAE (0.0835), unscaled WMAE (1710.73).



# TFT 

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. გაერთიანდა Store და Date-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5 შეივსო 0-ებით (არ არის markdown მოვლენა), CPI და Unemployment შეივსო მედიანით.



IsHoliday გარდაიქმნა 0/1-ად.



Type სვეტი არ იყო ხელმისაწვდომი გაერთიანებულ მონაცემებში, ამიტომ გამოყენებულია placeholder (0).



დროის სერიების შექმნა: გამოყენებულია darts ბიბლიოთეკა მაღაზია-განყოფილების წყვილებისთვის დროის სერიების შესაქმნელად.





Target: Weekly_Sales (მხოლოდ სასწავლო მონაცემებისთვის).



Past Covariates: Temperature, Fuel_Price, MarkDown1-5, CPI, Unemployment, Type, IsHoliday.



Future Covariates: IsHoliday, თვის one-hot თვისებები, კვირის ნომერი.



მონაცემთა ნაკრები:





სასწავლო: 421,570 ნიმუში (ჯამური).



ტესტის: 115,064 ნიმუში.



შეიქმნა დროის სერიები თითოეული მაღაზია-განყოფილებისთვის (მინიმუმ 16 დროის ნაბიჯი სასწავლოდ, 1 ტესტისთვის).

მოდელის არქიტექტურა





TFT (Temporal Fusion Transformer) მოდელი:





გამოყენებულია darts.models.TFTModel.



პარამეტრები:





input_chunk_length=12 (12-კვირიანი lookback).



output_chunk_length=4 (4-კვირიანი პროგნოზი).



hidden_size=16 (ეფექტურობისთვის).



lstm_layers=1.



num_attention_heads=4.



dropout=0.1.



batch_size=32.



n_epochs=10.



add_relative_index=True.



გამოყენებულია GPU (თუ ხელმისაწვდომია).



ზარალი: ნაგულისხმევი (MAE darts-ის მიხედვით).



ტრენინგი:





მოდელი გაწვრთნილია ყველა სასწავლო სერიაზე ერთდროულად.



WandB მონიტორინგი, ლოგირებულია სერიების რაოდენობა და ვალიდაციის WMAE.

შედეგები





საბოლოო მეტრიკები:





ვალიდაციის WMAE: გამოთვლილია ბოლო 4 კვირის გამოყენებით, მაგრამ ზუსტი მნიშვნელობა არ არის მოწოდებული.



Public Score: არ არის მოწოდებული, თუმცა ცნობილია, რომ შედეგები ცუდი იყო.



ანალიზი:





TFT მოდელის მარტივმა კონფიგურაციამ (hidden_size=16, lstm_layers=1, 10 ეპოქა) შესაძლოა ვერ შეძლო რთული სეზონური ნიმუშების ან მაღაზია-განყოფილების სპეციფიკური ნიმუშების აღქმა.



Type სვეტის არარსებობამ შესაძლოა შეამცირა მოდელის სიზუსტე, რადგან მაღაზიის ტიპი მნიშვნელოვანი თვისებაა.



მოკლე ტრენინგის ხანგრძლივობა (10 ეპოქა) და მცირე მოდელის ზომა შეიძლება იყოს ცუდი შედეგების მიზეზი. მაგრამ გამოწვევებისა და დროის უქონლობის გამო მოგვიწია სწრაფი ტრენინგით საუკეთესო მოდელის პოვნა.



დამატებითი თვისებები (მაგ., lagged გაყიდვები) არ იყო გამოყენებული, რამაც შესაძლოა შეამცირა მოდელის ეფექტურობა.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





გაერთიანდა test.csv, features.csv, stores.csv.



MarkDown1-5 შეივსო 0-ებით, CPI და Unemployment მედიანით.



IsHoliday გარდაიქმნა 0/1-ად, Type placeholder (0).



შეიქმნა დროის სერიები darts-ის გამოყენებით.



პროგნოზი:





TFT მოდელის გამოყენებით გენერირებულია პროგნოზები თითოეული მაღაზია-განყოფილებისთვის.



პროგნოზები შეზღუდულია არაუარყოფით მნიშვნელობებზე.



გაგზავნის ფაილი:





შეიქმნა walmart_submission.csv.



ლოგირებულია WandB-ში.

