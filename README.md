# Walmart Recruiting - Store Sales Forecasting

პროექტის მიმოხილვა

ეს პროექტი წარმოადგენს Kaggle-ის კონკურსს „Walmart Recruiting - Store Sales Forecasting“, სადაც მიზანია Walmart-ის მაღაზიების ყოველკვირეული გაყიდვების პროგნოზირება სხვადასხვა მაღაზიისა და განყოფილებისთვის. პროექტის ფარგლებში გამოცდილია სხვადასხვა მოდელის არქიტექტურა Deep Learning Models - N-BEATS, Temporal Fusion Transformer, PatchTST, DLinear
Tree-Based Models - LightGBM, XGBoost Classical Statistical Time-Series Models - ARIMA, SARIMA, Prophet.

გამოყენებული მიდგომები

# 0. მონაცემთა წინასწარი დამუშავება (DataExploration)

მონაცემთა შეერთება: train.csv, features.csv, stores.csv ფაილები გაერთიანდა ერთ მონაცემთა ნაკრებად

საბოლოოდ მიიღებოდა მონაცემები 421570 სტრიქონითა და 16 სვეტით

სულ იყო 45 განსხვავებული მაღაზია და 81 დეპარტამენტი

მონაცემებში თარიღები საჭიროებდნენ კონვერტაციას: თარიღის ველები გარდაიქმნა datetime ფორმატში.

ასევე Weekly sales-ებში გვქონდა უარყოფითი მნიშვნელობები რომლებიც მონაცემების მხოლოდ 0.3% შეადგენდა ამიტომ მათი მოშორება ლოგიკური იყო

დავაკვირდით საშუალო თვიურ გაყიდვებს წლების მიხედვით. ინფორმაცია მოცემული იყო 2010 წლის მარტიდან 2012 წლის ოქტომბრის ჩათვლით და ყოველი თვისთვის გაყიდვები მერყეობდა 14k-20k

ამის შემდგომ ვნახეთ გაყიდვების მნიშვნელობების რაოდენობები და უმეტესად ისინი მერყეობდა 0-დან 50k-მდე

ასევე შევისწავლეთ გაყიდვების მაქსიმალური მნიშვნელობები და საშუალოები მაღაზიებისა და დეპარტამენტების მიხედვით და აღმოჩნდა , რომ იმ მაღაზიებსა და დეპარტამენტებს რომლებსაც ყველაზე
დიდი გაყიდვები უფიქსირდებოდათ საშუალოებში ყველაზე მაღალი არ ჰქონდა.

ასევე გაყიდვები დღესასწაულების კვირებში მატულობდა მაგრამ მთლიან მონაცემებთან შედარებიტ ეს მატება შესამჩნევი არ იყო

ხოლო რაც შეეხება მაღაზიის ტიპებს გაყიდვებში აქ შესამჩნევი განსხვავება იყო A ტიპის მაღაზიების გაყიდვები საგრძნობლად მაღალი იყო B და C ტიპის მაღაზიებთან შედარებით 

შემდგომ შევისწავლეთ კორელაცია Markdown-ებსა და გაყიდვებს შორის და აღმოჩნდა რომ ისინი დიდად კორელირებულები არ იყვნენ, იგივე რამ ხდებოდა feature-ების შემთხვევაში, ანუ მათ დიდი გავლენა არ ექნებოდათ prediction-ზე

და მაში კარგად დასარწმუნებლად გამოვიტანეთ Fuel Price, CPI , Unemployment , Temperature ეფექტების ნახაზებიც.





# 1. XGBoost 

DataPreprocessing 

დამატებულია დროის ფუნქციები: წელი, თვე, კვირა, დღე, სადღესასწაულო დღეების სიახლოვე (მაგ., ნოემბრის მადლიერების დღე, შობა).

Markdown-ის მონაცემების ნაკლოვანებების აღნიშვნა და შევსება (SimpleImputer-ით ან მედიანით).

Lag და Rolling Mean ფუნქციების დამატება გაყიდვების ისტორიის გათვალისწინებით (მაგ., Sales_Lag_1, Sales_Rolling_Mean_3).

დამატებულია სინუსოიდური ფუნქციები (sin_13, cos_13, sin_23, cos_23).

კატეგორიული ცვლადები: Type ცვლადი გარდაიქმნა რიცხვით ფორმატში (OrdinalEncoder-ით).

მოდელის არქიტექტურები

აღწერა: გამოყენებულია XGBRegressor ჰიპერპარამეტრების ოპტიმიზაციით Optuna-ს გამოყენებით. TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.1


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4300.16

# 2. LightGBM

DataPreprocessing

იგივე რაც xgboost-ის შემთხვევაში

მოდელის არქიტექტურები

აღწერა: გამოყენებულია LightGBM . TimeSeriesSplit გამოყენებულია დროის სერიების სპეციფიკის გათვალისწინებით.

ჰიპერპარამეტრები:

n_estimators: 1000


max_depth: 6


learning_rate: 0.5


subsample: 0.9


colsample_bytree: 0.8


min_child_weight: 2


reg_alpha: 0.1


reg_lambda: 0.1


n_jobs=-1


შედეგები:

Validation WMAE: 4969.7372343221805




# 3. ARIMA

------------------ approach 1 ------------------


მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. გაერთიანდა Store, Date და IsHoliday-ზე.



გაწმენდა:





Date გარდაიქმნა datetime ფორმატში.



Weekly_Sales ხარვეზები შეივსო ffill-ით თითოეულ მაღაზია-განყოფილების ჯგუფში; დარჩენილი ხარვეზები (თუ იყო) საშუალო მნიშვნელობით.



სხვა ცვლადების (MarkDown1-5, CPI, Unemployment) ხარვეზები არ დამუშავებულა.



ფილტრაცია: მაღაზია-განყოფილების წყვილები, რომლებსაც ჰქონდა <10 ჩანაწერი, გამოირიცხა (3167 valid pair).



დროის სერიების მომზადება:





თითოეული მაღაზია-განყოფილებისთვის შეიქმნა დროის სერია Weekly_Sales-ით, Date ინდექსით (W-FRI სიხშირე).



სტაციონარულობის შემოწმება: ADF ტესტი (5% მნიშვნელობის დონე), 2275 სტაციონარული, 892 არასტაციონარული სერია.



მონაცემთა გაყოფა: 80% სასწავლო, 20% ვალიდაციისთვის, თარიღების მიხედვით.

მოდელის არქიტექტურა





ARIMA მოდელი:





ორდერი: (1,0,2) ყველა მაღაზია-განყოფილებისთვის.



ტრენინგი: გაწვრთნილია 10 მაღაზია-განყოფილების წყვილზე (subset) გამოთვლების დაჩქარებისთვის.



ვალიდაცია: პროგნოზები გენერირებულია ვალიდაციის პერიოდისთვის.



ზარალი: WMAE (წონები: 5 დღესასწაულებზე, 1 სხვა დღეებზე).



Fallback: თუ ARIMA ვერ გაწვრთნილა, გამოყენებულია ბოლო ცნობილი მნიშვნელობა ან განყოფილების საშუალო.

შედეგები





საბოლოო მეტრიკები:





Overall WMAE: 4254.3269 (10 წყვილზე).



Public Score: 4901.43392.



ანალიზი:





მარტივი ARIMA(1,0,2) გამოყენებულია შეზღუდულ subset-ზე, რამაც შეიძლება შეამცირა განზოგადება.



არასტაციონარულ სერიებზე მოდელის შესრულება შეიძლება გაუმჯობესდეს დიფერენცირებით.


------------------ approach 2 ------------------


მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან.



გაწმენდა:





Date გარდაიქმნა datetime ფორმატში.



MarkDown1-5, CPI, Unemployment ხარვეზები შეივსო მედიანებით.



დაემატა სპეციფიური დღესასწაულის ფლაგები (Super Bowl, Labor Day, Thanksgiving, Christmas).



Weekly_Sales გაწმენდა: გამოყენებულია IQR მეთოდი გარე მნიშვნელობების შესაზღუდად.



Weekly_Sales ხარვეზები შეივსო ffill-ით, შემდეგ საშუალოთი (თუ საჭირო იყო).



ფილტრაცია: 3167 valid pair (≥10 ჩანაწერი).



დროის სერიების მომზადება:





დროის სერიები Weekly_Sales-ით, W-FRI სიხშირით.



ADF ტესტი: 2261 სტაციონარული, 906 არასტაციონარული.



მონაცემთა გაყოფა: 80% სასწავლო, 20% ვალიდაციისთვის.

მოდელის არქიტექტურა





ARIMA მოდელი:





ორდერები: (1,0,2), (0,1,2), (1,1,1), (0,1,1) ტესტირება 100 წყვილზე, (1,0,2) ყველა დანარჩენზე.



ტრენინგი: batch-ებით (500 წყვილი) გაწვრთნილია 3167 წყვილზე.



ზარალი: WMAE.



Fallback: ბოლო მნიშვნელობა ან გლობალური საშუალო (13670.12).

შედეგები





საბოლოო მეტრიკები:





Overall WMAE: 1763.8796.



Public Score: 6765.77723.



ანალიზი:





გაუმჯობესებული WMAE მარტივ მიდგომასთან შედარებით, სავარაუდოდ, გაწმენდისა და დღესასწაულის ფლაგების გამო.



მრავალი ორდერის ტესტირებამ გააუმჯობესა მოდელის ადაპტაცია.



------------------ approach 3 ------------------


მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები.



გაწმენდა:





Date გარდაიქმნა datetime-ად.



MarkDown1-5, CPI, Unemployment ხარვეზები შეივსო მედიანებით.



Weekly_Sales ხარვეზები: ffill, შემდეგ საშუალო.



ფილტრაცია: 3167 valid pair (≥10 ჩანაწერი).



დროის სერიების მომზადება:





W-FRI სიხშირე, ADF ტესტი: 2275 სტაციონარული, 892 არასტაციონარული.



მონაცემთა გაყოფა: 80% სასწავლო, 20% ვალიდაციისთვის.

მოდელის არქიტექტურა





ARIMA მოდელი:





ორდერები: (1,0,2), (0,1,2), (1,1,1), (0,1,1) 100 წყვილზე, (1,0,2) დანარჩენზე.



ტრენინგი: batch-ებით (500 წყვილი), 3167 წყვილზე.



Holiday Adjustment: 1.5x მულტიპლიკატორი დღესასწაულებზე.



ზარალი: WMAE.



Fallback: ბოლო მნიშვნელობა ან გლობალური საშუალო (16005.54).

შედეგები





საბოლოო მეტრიკები:





Overall WMAE: 2483.8008.



Public Score: 6485.65868.



ანალიზი:





Holiday adjustment-მა გააუარესა WMAE, შესაძლოა, ზოგადი 1.5x მულტიპლიკატორის გამო.



მრავალი ორდერის ტესტირება გაგრძელდა, მაგრამ არასტაციონარულ სერიებზე შესრულება ცვალებადია.



------------------ approach 4 ------------------


მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები.



გაწმენდა:





Date გარდაიქმნა datetime-ად.



Weekly_Sales ხარვეზები: ffill, შემდეგ საშუალო.



MarkDown1-5, CPI, Unemployment ხარვეზები არ დამუშავებულა.



ფილტრაცია: 3167 valid pair (≥10 ჩანაწერი).



დროის სერიების მომზადება:





W-FRI სიხშირე, ADF ტესტი: 2275 სტაციონარული, 892 არასტაციონარული.



მონაცემთა გაყოფა: 80% სასწავლო, 20% ვალიდაციისთვის.

მოდელის არქიტექტურა





ARIMA მოდელი:





ორდერი: (1,0,2) 10 წყვილზე.



ტრენინგი: შეზღუდულია 10 წყვილზე.



ზარალი: WMAE.



Fallback: ბოლო მნიშვნელობა ან განყოფილების საშუალო (16005.54).

შედეგები





საბოლოო მეტრიკები:





Overall WMAE: 4254.3269.



Public Score: 4901.43392.



------------------ approach 5 ------------------



ი შეივსო ffill/bfill-ით, შემდეგ საშუალოთი.



Weekly_Sales ხარვეზები: ffill/bfill, შემდეგ განყოფილების საშუალოთი.



ფილტრაცია: 3167 valid pair (≥10 ჩანაწერი).



დროის სერიების მომზადება:





დროის სერიები Weekly_Sales-ით, W-FRI სიხშირით.



ADF ტესტი: 2275 სტაციონარული, 892 არასტაციონარული.



მონაცემთა გაყოფა: ვალიდაციის გაყოფა თარიღის მიხედვით (cutoff: 2012-09-01).

მოდელის არქიტექტურა





ARIMA მოდელი:





ორდერები: (1,0,2), (1,0,1), (0,1,2), (1,1,1) ტესტირება პირველ 100 წყვილზე, (1,0,2) ყველა დანარჩენზე.



ტრენინგი: batch-ებით (500 წყვილი), გაწვრთნილია 3167 წყვილზე.



Holiday Adjustment: განყოფილებებისთვის სპეციფიური მულტიპლიკატორები, გამოთვლილი როგორც დღესასწაულისა და არადღესასწაულის გაყიდვების თანაფარდობა (default: 1.5).



ზარალი: WMAE.



Fallback: ბოლო მნიშვნელობა ან განყოფილების მედიანა, თუ მედიანა არ არის, გლობალური საშუალო (16005.54).

შედეგები





საბოლოო მეტრიკები:





Overall WMAE: 1931.0866.



Public Score: 4680.49545.



ანალიზი:





გაუმჯობესებული WMAE მიდგომა 4-თან შედარებით, განყოფილებებისთვის სპეციფიური holiday adjustment-ისა და გაწმენდის გამო.



მრავალი ორდერის ტესტირებამ და batch-ებით ტრენინგმა გააუმჯობესა სტაბილურობა.



არასტაციონარულ სერიებზე შესრულება კვლავ ცვალებადია.

გაგზავნა



----------------- შედარება და დასკვნები -----------------


მიდგომა 5 აჩვენებს საუკეთესო WMAE-ს (1931.0866) განყოფილებებისთვის სპეციფიური holiday adjustment-ისა და გაწმენდის გაუმჯობესებული სტრატეგიების გამო.



მიდგომა 2 და მიდგომა 3 უკეთესია, ვიდრე მიდგომა 1 და მიდგომა 4, მაგრამ holiday adjustment-ის ზოგადი მულტიპლიკატორი (1.5) მიდგომა 3-ში ნაკლებად ეფექტური იყო.



საერთო გაუმჯობესების სფეროები:





არასტაციონარული სერიებისთვის დიფერენცირების ან SARIMA-ს გამოყენება.



განყოფილებებისთვის სპეციფიური ორდერების ოპტიმიზაცია.



დღესასწაულის ეფექტების უფრო ზუსტი მოდელირება.





# 4. SARIMAX 

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

მონაცემთა შეერთება: train.csv, features.csv, და stores.csv ფაილები გაერთიანდა ერთ მონაცემთა ნაკრებად, რის შედეგადაც მიღებული იქნა 421,570 სტრიქონი და 16 სვეტი, 45 მაღაზიისა და 81 დეპარტამენტის მონაცემებით.

თარიღის კონვერტაცია: თარიღის ველები გარდაიქმნა datetime ფორმატში.

უარყოფითი გაყიდვების მოშორება: უარყოფითი Weekly_Sales მნიშვნელობები, რომლებიც 0.3%-ს შეადგენდა, ამოღებულ იქნა.

დღესასწაულის წონა: შეიქმნა IsHolidayWeight სვეტი, სადაც დღესასწაულის კვირებს ენიჭებოდა წონა 5, ხოლო ჩვეულებრივ კვირებს — 1.

დღესასწაულის ფუნქციები: დამატებულია სპეციფიური ფუნქციები ძირითადი დღესასწაულებისთვის (SuperBowl, LaborDay, Thanksgiving, Christmas), მათ შორის კვირისა და მიახლოებული კვირების (2 კვირა ადრე/შემდეგ) ნიშნულები.

დროის ფუნქციები: დამატებულია WeekOfYear, Month, Year, Quarter (მეორე მიდგომისთვის), ასევე ციკლური ფუნქციები (Week_sin, Week_cos, Month_sin, Month_cos) სეზონური ნიმუშების აღსაწერად.

გამოტოვებული მნიშვნელობების მართვა:

Temperature, Fuel_Price, CPI, Unemployment შეივსო მაღაზიისა და თვის/მაღაზიის საშუალო მნიშვნელობებით.

MarkDown სვეტები შეივსო 0-ებით, რადგან გამოტოვებული მნიშვნელობები სავარაუდოდ ნიშნავს ფასდაკლების არარსებობას.


ურთიერთქმედების ფუნქციები (მეორე მიდგომა): დამატებულია Temp_Unemployment და Holiday_Markdown, ასევე Total_Markdown ფუნქცია, რომელიც აერთიანებს ყველა MarkDown სვეტს.


მოდელის არქიტექტურები:

პირველი მიდგომა (Fast SARIMAX):

აღწერა: გამოყენებულია SARIMAX მოდელი მარტივი პარამეტრებით (order=(1,0,0), seasonal_order=(0,0,0,52)) გამოთვლების დასაჩქარებლად. მოდელი გაწვრთნილია თითოეული მაღაზია-დეპარტამენტის კომბინაციისთვის (3331 კომბინაცია).

ოპტიმიზაცია:

გამოყენებულია simple_differencing=True სწრაფი განსხვავებისთვის.

maxiter=50 და method='lbfgs' გამოთვლების დასაჩქარებლად.


ჩავარდნის მართვა: თუ მონაცემები არასაკმარისი (<20) ან თითქმის მუდმივი იყო, გამოყენებული იქნა საშუალო გაყიდვების მნიშვნელობა.

შედეგები:


Validation WMAE: 5034.1327


დამუშავების დრო: 4.1 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0




მეორე მიდგომა (Improved SARIMAX):

აღწერა: გაუმჯობესებული SARIMAX მოდელი გარე რეგრესორებით (Temperature, Fuel_Price, CPI, Unemployment, Total_Markdown, Holiday_Markdown, SuperBowl_Week, LaborDay_Week, Thanksgiving_Week, Christmas_Week, Week_sin, Week_cos, Month_sin, Month_cos). გამოყენებულია უფრო რთული პარამეტრები (order=(1,1,1), seasonal_order=(1,1,1,52)).

ფუნქციების გაუმჯობესება:

დღესასწაულის ფუნქციები გაძლიერდა დამატებითი წონებით (1/(i+1)) 3 კვირის განმავლობაში დღესასწაულამდე/შემდეგ.

ოპტიმიზაცია:

maxiter=100 უკეთესი კონვერგენციისთვის.

გარე რეგრესორების NaN-ების მართვა ffill/bfill-ით.

ჩავარდნის მართვა: თუ მონაცემები არასაკმარისი (<30) ან თითქმის მუდმივი იყო, გამოყენებული იქნა საშუალო გაყიდვები.


შედეგები:

Validation WMAE: 2379.8436


დამუშავების დრო: 5.0 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0


ხარისხის შემოწმება:


მინიმალური პროგნოზი: 0.00


მაქსიმალური პროგნოზი: 182,527.96


საშუალო პროგნოზი: 15,982.75


უარყოფითი პროგნოზები: 0


ძირითადი გაუმჯობესებები

მეორე მიდგომის უპირატესობა: გარე რეგრესორების, ციკლური ფუნქციებისა და ურთიერთქმედების ფუნქციების დამატებამ მნიშვნელოვნად გააუმჯობესა WMAE (5034.1327-დან 2379.8436-მდე) და Public Score (7900-დან 4900-მდე).

სიჩქარე: მიუხედავად გაუმჯობესებული მოდელის სირთულისა, დამუშავების დრო მხოლოდ 0.9 წუთით გაიწელა (4.1-დან 5.0 წუთამდე).

სტაბილურობა: ორივე მიდგომაში 3331-ვე მაღაზია-დეპარტამენტის კომბინაციისთვის მოდელის მორგება წარმატებული იყო, ჩავარდნების გარეშე.




მესამე მიდგომა 

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

ძირითადი მახასიათებლები: იგივე, რაც მეორე მიდგომაში, დამატებით:

გაუმჯობესებული გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციების მართვა: გამოყენებულია დეპარტამენტის დონის საშუალო გაყიდვები დღესასწაულის/არადღესასწაულის მიხედვით, როგორც სარეზერვო (fallback) მნიშვნელობა, როდესაც მაღაზია-დეპარტამენტის კომბინაცია არ არსებობს სასწავლო მონაცემებში.

უარყოფითი პროგნოზების გამოსწორება: ყველა პროგნოზი გარდაიქმნა 0-ზე მეტ ან ტოლი მნიშვნელობებად.

მონაცემთა ნაკრები: 421,570 სტრიქონი, 45 მაღაზია, 81 დეპარტამენტი.


მოდელის არქიტექტურა

აღწერა: SARIMAX მოდელი გაუმჯობესებული გარე რეგრესორებით (Total_Markdown, Holiday_Markdown, SuperBowl_Week, Thanksgiving_Week, Christmas_Week, Week_sin, Week_cos). გამოყენებულია order=(1,0,2) და seasonal_order=(1,1,1,52) სტაბილურობისა და სიზუსტის გასაუმჯობესებლად.

ჩავარდნის მართვა:

თუ მონაცემები <30 ან თითქმის მუდმივი იყო, გამოყენებული იქნა დღესასწაულის/არადღესასწაულის საშუალო მნიშვნელობები.

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციებისთვის გამოყენებული იქნა დეპარტამენტის დონის საშუალო გაყიდვები.


ოპტიმიზაცია:

maxiter=100, method='lbfgs', optim_score='harvey' უკეთესი კონვერგენციისთვის.
გარე რეგრესორების NaN-ები შეივსო ffill/bfill-ით.


შედეგები:


Validation WMAE: 2494.3902


Public Score: 4600


დამუშავების დრო: 5.3 წუთი


წარმატებული მორგებები: 3331


ჩავარდნები: 0


გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციები: 11 (დაფარული დეპარტამენტის საშუალოებით)


ხარისხის შემოწმება:



მინიმალური პროგნოზი: 0.00


მაქსიმალური პროგნოზი: 263,476.20


საშუალო პროგნოზი: 15,986.92


უარყოფითი პროგნოზები: 0





ძირითადი გაუმჯობესებები

გაუმჯობესებული WMAE: 2379.8436-დან (მეორე მიდგომა) 2494.3902-მდე, მაგრამ Public Score გაუმჯობესდა 4900-დან 4600-მდე.

გამოტოვებული კომბინაციების მართვა: დეპარტამენტის დონის საშუალოებმა უზრუნველყო საიმედო სარეზერვო პროგნოზები 11 გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციისთვის.

სტაბილურობა: ყველა 3331 კომბინაციისთვის მოდელის მორგება წარმატებული იყო ჩავარდნების გარეშე.


მეოთხე მიდგომა (SARIMAX + Random Forest Hybrid)

მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

ძირითადი მახასიათებლები:

მეხსიერების ოპტიმიზაცია: გამოყენებულია ოპტიმიზებული მონაცემთა ტიპები (int8, float32, int32) მეხსიერების მოხმარების შესამცირებლად.

მაღაზიისა და დეპარტამენტის სტატისტიკა: დამატებულია მაღაზიისა და დეპარტამენტის დონის საშუალო და სტანდარტული გადახრები (Store_Sales_Mean, Store_Sales_Std, Dept_Sales_Mean, Dept_Sales_Std).

მაღაზიის ტიპის dummy ცვლადები: Type_A, Type_B, Type_C გარდაიქმნა int8-ად.

დაგვიანებული (Lagged) ფუნქციები: დამატებულია Weekly_Sales-ის 1-კვირიანი დაგვიანებული მნიშვნელობები (Lagged_Sales).

მოძრავი საშუალო (Rolling Mean): 4-კვირიანი მოძრავი საშუალო Weekly_Sales-ისთვის.

გამოტოვებული მნიშვნელობების მართვა:

Temperature, Fuel_Price, CPI, Unemployment შეივსო მაღაზიისა და თვის საშუალოებით.

MarkDown სვეტები შეივსო 0-ებით.

მონაცემთა ნაკრები: იგივე 421,570 სტრიქონი, 45 მაღაზია, 81 დეპარტამენტი.



მოდელის არქიტექტურა

აღწერა: ჰიბრიდული მიდგომა, რომელიც აერთიანებს SARIMAX-სა და RandomForestRegressor-ს:

SARIMAX: გამოყენებულია მაღალი ვარიაციის (>1000) და საკმარისი მონაცემების (≥50) მქონე სერიებისთვის, order=(1,0,1), seasonal_order=(0,1,1,52). 

Random Forest: გამოყენებულია, როგორც სარეზერვო, როდესაც SARIMAX-ის WMAE > 10,000 ან მონაცემები არ არის საკმარისი SARIMAX-ისთვის. მახასიათებლები: Total_Markdown, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday, WeekOfYear, Month, 

Size, Type_A, Type_B, Type_C, Week_sin, Week_cos, Month_sin, Month_cos, Store_Sales_Mean, Dept_Sales_Mean, Lagged_Sales, დაგვიანებული და მოძრავი საშუალო ფუნქციები.

სტატისტიკური სარეზერვო: გამოყენებულია, როდესაც ორივე მოდელი ვერ მუშაობს, დღესასწაულის/არადღესასწაულის საშუალოებით.


ჩავარდნის მართვა:

თუ SARIMAX ჩავარდა ან WMAE > 10,000, გამოყენებული იქნა Random Forest.

თუ Random Forest-ისთვის მონაცემები <8, გამოყენებული იქნა სტატისტიკური საშუალო.

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციებისთვის: 0.6 * დეპარტამენტის საშუალო + 0.4 * მაღაზიის საშუალო.



ოპტიმიზაცია:

SARIMAX: maxiter=50, method='lbfgs', gtol=1e-6.

Random Forest: n_estimators=50, max_depth=6, min_samples_split=5, min_samples_leaf=3, max_features='sqrt'.

მეხსიერების მართვა: პარტიული (batch) დამუშავება (500 კომბინაცია თითო პარტიაში) და gc.collect() მეხსიერების გასაწმენდად.


შედეგები:


Validation WMAE: არ არის მოცემული (სავარაუდოდ, შედარებადია მესამე მიდგომასთან).

დამუშავების დრო: 5.3 წუთი (შედარებადი მესამე მიდგომასთან).

მოდელის განაწილება:

SARIMAX: გამოყენებული მაღალი ვარიაციის სერიებისთვის.

Random Forest: გამოყენებული SARIMAX-ის ჩავარდნის ან სუსტი შედეგის შემთხვევაში.

სტატისტიკური: გამოყენებული მცირე მონაცემების ან მარტივი სერიებისთვის.


ხარისხის შემოწმება:

მინიმალური პროგნოზი: 0.00

მაქსიმალური პროგნოზი: მაღალი (ზუსტი მნიშვნელობა არ არის მოცემული).

საშუალო პროგნოზი: 15,986.92 (მსგავსი მესამე მიდგომისა).

უარყოფითი პროგნოზები: 0

გამოტოვებული მაღაზია-დეპარტამენტის კომბინაციები: გარკვეული რაოდენობა (ზუსტი რიცხვი არ არის მოცემული), დაფარული დეპარტამენტისა და მაღაზიის საშუალოებით.



ძირითადი გაუმჯობესებები

ჰიბრიდული მიდგომა: SARIMAX-ისა და Random Forest-ის კომბინაციამ უზრუნველყო მოქნილობა, სადაც SARIMAX გამოიყენებოდა ძლიერი სეზონური ნიმუშებისთვის, ხოლო Random Forest — უფრო რთული, არაწრფივი ურთიერთქმედებებისთვის.

მეხსიერების ოპტიმიზაცია: მონაცემთა ტიპების შემცირებამ და პარტიულმა დამუშავებამ გააუმჯობესა ეფექტურობა.

გაძლიერებული ფუნქციები: დაგვიანებული და მოძრავი საშუალო ფუნქციებმა გააუმჯობესა Random Forest-ის მუშაობა.

ჩავარდნის მართვა: სამსაფეხურიანი სარეზერვო სისტემა (SARIMAX → Random Forest → სტატისტიკური) უზრუნველყოფდა ყველა შემთხვევის დაფარვას.




# 5. Prophet


მონაცემთა წინასწარი დამუშავება (Data Preprocessing)

მონაცემთა შეერთება:
train.csv, test.csv, features.csv, და stores.csv გაერთიანდა ერთ მონაცემთა ნაკრებად (combined_df) Store და Date სვეტებზე left join-ის გამოყენებით.

დამატებულია Set სვეტი (train ან test) მონაცემთა წყაროს განსასხვავებლად.

მონაცემთა ნაკრები შეიცავს 421,570 სტრიქონს, 45 მაღაზიას და 81 დეპარტამენტს.

თარიღის კონვერტაცია:

Date სვეტი გარდაიქმნა datetime ფორმატში.


Prophet-ისთვის მომზადება:

Date გადაკეთდა ds და Weekly_Sales გადაკეთდა y Prophet-ის ფორმატისთვის.

NaN მნიშვნელობები Weekly_Sales-ში შეივსო 0-ებით, რადგან Prophet არ იღებს NaN-ებს.

მონაცემთა დახარისხება:

მონაცემები დახარისხდა Store, Dept, და Date-ის მიხედვით.

გამოტოვებული მნიშვნელობები:

features.csv-ისა და stores.csv-ის გაერთიანებისას გამოტოვებული მნიშვნელობები არ იყო სპეციფიურად დამუშავებული, გარდა Weekly_Sales-ისა test.csv-ში (შეივსო NaN-ებით, როგორც placeholder).


ფუნქციები:

არ გამოყენებულა გარე რეგრესორები ან დამატებითი ფუნქციები (მაგ., Temperature, CPI, MarkDown), რადგან Prophet-ის ძირითადი მოდელი ფოკუსირებულია მხოლოდ ds და y სვეტებზე.



მოდელის არქიტექტურა

აღწერა:
გამოყენებულია Prophet მოდელი თითოეული მაღაზია-დეპარტამენტის კომბინაციისთვის (3331 კომბინაცია).
Prophet-ის პარამეტრები:

yearly_seasonality=True (ჩართულია წლიური სეზონურობა).

ნაგულისხმევი weekly_seasonality და daily_seasonality გამორთულია, რადგან მონაცემები ყოველკვირეულია.

მოდელი გაწვრთნილია train მონაცემებზე (ds, y) და პროგნოზი გაკეთდა test მონაცემების თარიღებისთვის.


ჩავარდნის მართვა:

თუ მაღაზია-დეპარტამენტის კომბინაციას ჰქონდა <2 მონაცემთა წერტილი, ის გამოტოვებული იქნა.
გამოტოვებული კომბინაციებისთვის (test-ში, რომლებიც არ იყო train-ში), პროგნოზები შეივსო 0-ებით sample_submission-ის გამოყენებით.


ოპტიმიზაცია:

Prophet-ის ნაგულისხმევი ოპტიმიზაცია გამოყენებულია (method='lbfgs', iter=10000).

უარყოფითი პროგნოზები გარდაიქმნა 0-ზე (clip(lower=0)).

პროგნოზები დამრგვალდა 2 ათწილადამდე.


ვალიდაცია:


გამოყენებულია ბოლო 10 კვირა train მონაცემებიდან ვალიდაციისთვის (Store 1, Dept 1).


MAE: 1560.9705


RMSE: 2011.2182


შედეგები:


Validation WMAE: არ არის მოცემული (MAE და RMSE გამოთვლილია მხოლოდ Store 1, Dept 1-ისთვის).


Public Score: არ არის მოცემული.


დამუშავების დრო: არ არის მოცემული, მაგრამ Prophet-ის მოდელი ზოგადად უფრო ნელია, ვიდრე SARIMAX, მრავალი კომბინაციის გამო.



ძირითადი გაუმჯობესებები

Prophet-ის გამოყენება:

Prophet-ის სიძლიერეა მისი მარტივი გამოყენება და სეზონური ნიმუშების (განსაკუთრებით წლიური) ავტომატური ამოცნობა, რაც ამცირებს ფუნქციების ხელით შექმნის საჭიროებას.

თუმცა, ამ მიდგომაში არ გამოყენებულა გარე რეგრესორები (Temperature, CPI, MarkDown), რაც შეიძლება შეზღუდავდეს სიზუსტეს.


შეზღუდვები

გარე რეგრესორების არარსებობა: Prophet-ის მოდელმა არ გამოიყენა features.csv-ის ცვლადები (მაგ., Temperature, CPI, MarkDown), რაც შეიძლება ზღუდავდეს მის სიზუსტეს SARIMAX-ის მიდგომებთან შედარებით.
ვალიდაციის შეზღუდვა: MAE და RMSE გამოთვლილია მხოლოდ ერთი მაღაზია-დეპარტამენტისთვის (Store 1, Dept 1), რაც არ წარმოადგენს ყოვლისმომცველ შეფასებას.
გამოტოვებული მნიშვნელობები: გამოტოვებული კომბინაციებისთვის 0-ის გამოყენება ნაკლებად ზუსტია, ვიდრე მესამე/მეოთხე მიდგომების საშუალოებზე დაფუძნებული მიდგომა.
სიჩქარე: Prophet-ის მრავალი მოდელის გაწვრთნა (3331 კომბინაციისთვის) შეიძლება უფრო ნელი იყოს, ვიდრე SARIMAX, თუმცა ზუსტი დრო არ არის მოცემული.

შედარება წინა მიდგომებთან

სიზუსტე: Prophet-ის MAE (1560.9705) Store 1, Dept 1-ისთვის უკეთესია, ვიდრე SARIMAX-ის Validation WMAE (2379.8436-2494.3902), მაგრამ ეს არ არის ყოვლისმომცველი, რადგან ვალიდაცია შესრულდა მხოლოდ ერთ კომბინაციაზე.
Public Score: არ არის მოცემული, მაგრამ მესამე/მეოთხე მიდგომების 4600-თან შედარებით, Prophet-ის სიზუსტე შეიძლება იყოს ნაკლები გარე რეგრესორების გამოყენების გარეშე.
ფუნქციები: Prophet-ის მარტივი მიდგომა (მხოლოდ ds, y) ნაკლებად მდიდარია, ვიდრე SARIMAX-ისა და Random Forest-ის ფუნქციები (მაგ., Total_Markdown, Lagged_Sales, Week_sin).
გამოთვლითი ეფექტურობა: Prophet-ის მრავალი მოდელის გაწვრთნა შეიძლება უფრო მეტ დროს მოითხოვდეს, განსაკუთრებით 3331 კომბინაციისთვის, თუმცა ოპტიმიზაციის სპეციფიური ზომები (მაგ., პარტიული დამუშავება) არ გამოყენებულა.

დასკვნა
Prophet-ის მიდგომა გთავაზობთ მარტივ, ავტომატიზებულ გადაწყვეტას სეზონური ნიმუშებისთვის, მაგრამ მისი ეფექტურობა შეიძლება შეიზღუდოს გარე ცვლადების გამოყენების არარსებობით და გამოტოვებული კომბინაციებისთვის 0-ის გამოყენებით. SARIMAX-ისა და Random Forest-ის ჰიბრიდული მიდგომები (მესამე/მეოთხე) უფრო ზუსტია, რადგან ისინი იყენებენ მდიდარ ფუნქციებს და უკეთეს სარეზერვო სტრატეგიებს.





# 6. DLinear 

---------------------approache 1---------------------

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემთა ნაკრები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. მონაცემები გაერთიანდა Store და Date ცვლადებზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-MarkDown5, CPI, Unemployment, Temperature, Fuel_Price, Size შეივსო 0-ებით ან საშუალო მნიშვნელობებით.



IsHoliday გარდაიქმნა 0/1-ად, Type გარდაიქმნა რიცხვებად (A=0, B=1, C=2).



გამოყენებულია StandardScaler Weekly_Sales-ისა და თვისებების ნორმალიზაციისთვის, clipping [-1e5, 1e5].



დროის სერიების შექმნა: მონაცემები გაიყო მაღაზია-განყოფილების წყვილებად (Store, Dept). შეიქმნა უწყვეტი ყოველკვირეული მონაცემები pd.date_range-ის გამოყენებით, ხარვეზები შეივსო ffill-ით ან 0-ებით.



თვისებები: 12 ეგზოგენური თვისება (Temperature, Fuel_Price, CPI, Unemployment, MarkDown1-5, Size, Type, IsHoliday).



მონაცემთა ნაკრები:





train: 251,133 ნიმუში



validation: 316,241 ნიმუში

მოდელის არქიტექტურა





DLinear მოდელი:





Trend: ერთი nn.Linear(seq_len, pred_len) ფენა.



Seasonal: ერთი nn.Linear(seq_len, pred_len) ფენა.



Exogenous: ერთი nn.Linear(seq_len * n_features, pred_len) ფენა.



გამომავალი: trend + seasonal + exogenous.



პარამეტრები:





seq_len=36, pred_len=6, n_features=12.



Adam ოპტიმიზატორი lr=0.001.



ზარალი: MSE + WMAE (Weighted Mean Absolute Error, წონები: 4 დღესასწაულებისთვის, 1 სხვა დღეებისთვის).



ტრენინგი:





20 ეპოქა, batch size=32.



გრადიენტის clipping (max_norm=1.0).



WandB მონიტორინგი.

შედეგები





საბოლოო მეტრიკები (ეპოქა 20):





Train MSE: 0.0956, Train WMAE: 0.2780



Val MSE: 0.1057, Val WMAE: 0.2752



Public Score: 6098



ანალიზი:





Train WMAE სტაბილური (~0.277-0.289), Val WMAE მერყეობდა (0.2376-0.2935).



მარტივი არქიტექტურა შეიძლება ზღუდავდეს რთული ნიმუშების აღქმას.



მაღალი Val WMAE ეპოქა 6-ზე (0.2935) მიუთითებს გადაჭარბებულ მორგებაზე ან მონაცემთა ხარვეზებზე.



---------------------approache 2---------------------

მონაცემთა წინასწარი დამუშავება





განსხვავებები მიდგომა 1-ისგან:





დაემატა ოთხი სადღესასწაულო თვისება: SuperBowl, LaborDay, Thanksgiving, Christmas (1 თუ თარიღი ემთხვევა, 0 სხვა შემთხვევაში).



თვისებების რაოდენობა გაიზარდა 12-დან 16-მდე.



სხვა წინასწარი დამუშავება იდენტურია.



მონაცემთა ნაკრები:





სასწავლო: 251,133 ნიმუში



ვალიდაციის: 316,241 ნიმუში

მოდელის არქიტექტურა





DLinear მოდელი:





Trend: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით და dropout (0.1).



Seasonal: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით და dropout (0.1).



Exogenous: სამფენიანი MLP (seq_len * n_features -> 512 -> 256 -> pred_len) ReLU-ით და dropout (0.1).



გამომავალი: trend + seasonal + exogenous.



პარამეტრები:





seq_len=36, pred_len=6, n_features=16.



Adam ოპტიმიზატორი lr=0.0001.



ზარალი: MSE + 2 * WMAE.



Early stopping (patience=5) Val WMAE-ზე.



გრადიენტის clipping (max_norm=1.0).



ტრენინგი:





20 ეპოქა, batch size=32.



WandB მონიტორინგი unscaled WMAE-ით.

შედეგები





საბოლოო მეტრიკები (ეპოქა 20):





Train MSE: 0.0753, Train WMAE: 0.2026, Train WMAE Unscaled: 4148.68



Val MSE: 0.0585, Val WMAE: 0.1565, Val WMAE Unscaled: 3203.88



Public Score: 4906



ანალიზი:





Val WMAE გაუმჯობესდა (0.1565 vs 0.2752).



Unscaled WMAE (Train: 4148.68, Val: 3203.88) ზუსტი პროგნოზები.



ღრმა MLP და სადღესასწაულო თვისებები აუმჯობესებენ სეზონური ნიმუშების აღქმას.



Early stopping თავიდან აიცილებს გადაჭარბებულ მორგებას (საუკეთესო Val WMAE: 0.1560 ეპოქა 18).



---------------------  approache 3  ---------------------

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები Google Drive-დან. გაერთიანდა Store და Date-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5, CPI, Unemployment, Temperature, Fuel_Price, Size 0-ებით ან საშუალო მნიშვნელობებით.



IsHoliday გარდაიქმნა 0/1-ად, Type (A=0, B=1, C=2).



დაემატა სადღესასწაულო თვისებები: SuperBowl, LaborDay, Thanksgiving, Christmas.



დაემატა დროის თვისებები: WeekOfYear, Month, Year.



დაემატა სიახლოვის თვისებები: SuperBowl_Before/After, LaborDay_Before/After (±2 კვირა).



დაემატა lagged გაყიდვები: Lag1, Lag2, Lag4.



StandardScaler 26 თვისებაზე, clipping [-1e5, 1e5].



დროის სერიების შექმნა: გაიყო მაღაზია-განყოფილებებად, შეიქმნა უწყვეტი მონაცემები pd.date_range-ით.



თვისებები: 26 ეგზოგენური თვისება (Temperature, Fuel_Price, CPI, Unemployment, MarkDown1-5, Size, Type, IsHoliday, SuperBowl, LaborDay, Thanksgiving, Christmas, WeekOfYear, Month, Year, Lag1, Lag2, Lag4, SuperBowl_Before/After, LaborDay_Before/After).



მონაცემთა ნაკრები:





სასწავლო: 251,133 ნიმუში



ვალიდაციის: 316,241 ნიმუში

მოდელის არქიტექტურა





გაძლიერებული DLinear მოდელი:





Trend: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით, dropout (0.2).



Seasonal: სამფენიანი MLP (seq_len -> seq_len -> seq_len/2 -> pred_len) ReLU-ით, dropout (0.2).



Exogenous: Attention ფენა (feature_dim=26, attention_dim=128), შემდეგ სამფენიანი MLP (seq_len * n_features -> 512 -> 256 -> pred_len) ReLU-ით, dropout (0.2).



Holiday-Specific: სამფენიანი MLP (seq_len * 5 -> 256 -> pred_len) დღესასწაულებისთვის (IsHoliday, SuperBowl, LaborDay, Thanksgiving, Christmas).



Trend Decomposition: nn.AvgPool1d (kernel_size=7) ტრენდის გამოყოფისთვის.



კომბინაცია: nn.Linear(pred_len * 4, pred_len) ყველა კომპონენტის გაერთიანებისთვის.



პარამეტრები:





seq_len=36, pred_len=6, n_features=26, dropout=0.2, kernel_size=7.



Adam ოპტიმიზატორი lr=0.0001, weight_decay=1e-5.



ზარალი: MSE + 3 * WMAE.



ReduceLROnPlateau (factor=0.5, patience=3).



Early stopping (patience=10) Val WMAE-ზე.



გრადიენტის clipping (max_norm=1.0).



ტრენინგი:





50 ეპოქა, batch size=32.



WandB მონიტორინგი unscaled WMAE-ით.

შედეგები





საბოლოო მეტრიკები (ეპოქა 50):





Train MSE: 0.0476, Train WMAE: 0.1100, Train WMAE Unscaled: 2252.39



Val MSE: 0.0400, Val WMAE: 0.0835, Val WMAE Unscaled: 1710.73



Public Score: არ არის მოწოდებული.



ანალიზი:





მნიშვნელოვანი გაუმჯობესება Val WMAE (0.0835 vs 0.1565) და unscaled WMAE (1710.73 vs 3203.88).



Attention და სადღესასწაულო ფენა აუმჯობესებს თვისებების ურთიერთქმედებას.



Early stopping არ გააქტიურდა, საუკეთესო Val WMAE: 0.0833 ეპოქა 46.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





იგივე წინასწარი დამუშავება (26 თვისება, სკალირება, lagged გაყიდვები).



შეიქმნა თანმიმდევრობები, გამოყენებულია სასწავლო მონაცემები lagged-ისთვის.



პროგნოზი:





ჩაიტვირთა საუკეთესო მოდელი (enhanced_dlinear_model_best_v3.pth).



გენერირებული პროგნოზები პირველი კვირისთვის (pred_len=6).



განხორციელდა inverse transform scaler_sales-ით.



პროგნოზები შეზღუდულია არაუარყოფით მნიშვნელობებზე.



----------//შედარება მიდგომების//----------

ძირითადი განსხვავებები





features:





მიდგომა 1: 12 features.



მიდგომა 2: 16 features.



მიდგომა 3: 26 features (WeekOfYear, Month, Year, Lag1, Lag2, Lag4, SuperBowl_Before/After, LaborDay_Before/After).



არქიტექტურა:





მიდგომა 1: ხაზოვანი ფენები.



მიდგომა 2: სამფენიანი MLP ReLU-ით, dropout (0.1).



მიდგომა 3: სამფენიანი MLP, attention, სადღესასწაულო ფენა, ტრენდის გამოყოფა.



სწავლის სიჩქარე:





მიდგომა 1: lr=0.001.



მიდგომა 2: lr=0.0001.



მიდგომა 3: lr=0.0001 ReduceLROnPlateau-ით.



error:





მიდგომა 1: MSE + WMAE.



მიდგომა 2: MSE + 2 * WMAE.



მიდგომა 3: MSE + 3 * WMAE.



დამატებითი მექანიზმები:





მიდგომა 3: attention, სადღესასწაულო MLP, ტრენდის გამოყოფა.



ტრენინგის ხანგრძლივობა:





მიდგომა 1 & 2: 20 ეპოქა.



მიდგომა 3: 50 ეპოქა early stopping-ით (patience=10).



მეტრიკები:





მიდგომა 3: საუკეთესო Val WMAE (0.0835), unscaled WMAE (1710.73).



# 7. TFT 

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. გაერთიანდა Store და Date-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5 შეივსო 0-ებით (არ არის markdown მოვლენა), CPI და Unemployment შეივსო მედიანით.



IsHoliday გარდაიქმნა 0/1-ად.



Type სვეტი არ იყო ხელმისაწვდომი გაერთიანებულ მონაცემებში, ამიტომ გამოყენებულია placeholder (0).



დროის სერიების შექმნა: გამოყენებულია darts ბიბლიოთეკა მაღაზია-განყოფილების წყვილებისთვის დროის სერიების შესაქმნელად.





Target: Weekly_Sales (მხოლოდ სასწავლო მონაცემებისთვის).



Past Covariates: Temperature, Fuel_Price, MarkDown1-5, CPI, Unemployment, Type, IsHoliday.



Future Covariates: IsHoliday, თვის one-hot თვისებები, კვირის ნომერი.



მონაცემთა ნაკრები:





სასწავლო: 421,570 ნიმუში (ჯამური).



ტესტის: 115,064 ნიმუში.



შეიქმნა დროის სერიები თითოეული მაღაზია-განყოფილებისთვის (მინიმუმ 16 დროის ნაბიჯი სასწავლოდ, 1 ტესტისთვის).

მოდელის არქიტექტურა





TFT (Temporal Fusion Transformer) მოდელი:





გამოყენებულია darts.models.TFTModel.



პარამეტრები:





input_chunk_length=12 (12-კვირიანი lookback).



output_chunk_length=4 (4-კვირიანი პროგნოზი).



hidden_size=16 (ეფექტურობისთვის).



lstm_layers=1.



num_attention_heads=4.



dropout=0.1.



batch_size=32.



n_epochs=10.



add_relative_index=True.



გამოყენებულია GPU (თუ ხელმისაწვდომია).



ზარალი: ნაგულისხმევი (MAE darts-ის მიხედვით).



ტრენინგი:





მოდელი გაწვრთნილია ყველა სასწავლო სერიაზე ერთდროულად.



WandB მონიტორინგი, ლოგირებულია სერიების რაოდენობა და ვალიდაციის WMAE.

შედეგები





საბოლოო მეტრიკები:





ვალიდაციის WMAE: გამოთვლილია ბოლო 4 კვირის გამოყენებით, მაგრამ ზუსტი მნიშვნელობა არ არის მოწოდებული.



Public Score: არ არის მოწოდებული, თუმცა ცნობილია, რომ შედეგები ცუდი იყო.



ანალიზი:





TFT მოდელის მარტივმა კონფიგურაციამ (hidden_size=16, lstm_layers=1, 10 ეპოქა) შესაძლოა ვერ შეძლო რთული სეზონური ნიმუშების ან მაღაზია-განყოფილების სპეციფიკური ნიმუშების აღქმა.



Type სვეტის არარსებობამ შესაძლოა შეამცირა მოდელის სიზუსტე, რადგან მაღაზიის ტიპი მნიშვნელოვანი თვისებაა.



მოკლე ტრენინგის ხანგრძლივობა (10 ეპოქა) და მცირე მოდელის ზომა შეიძლება იყოს ცუდი შედეგების მიზეზი. მაგრამ გამოწვევებისა და დროის უქონლობის გამო მოგვიწია სწრაფი ტრენინგით საუკეთესო მოდელის პოვნა.



დამატებითი თვისებები (მაგ., lagged გაყიდვები) არ იყო გამოყენებული, რამაც შესაძლოა შეამცირა მოდელის ეფექტურობა.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





გაერთიანდა test.csv, features.csv, stores.csv.



MarkDown1-5 შეივსო 0-ებით, CPI და Unemployment მედიანით.



IsHoliday გარდაიქმნა 0/1-ად, Type placeholder (0).



შეიქმნა დროის სერიები darts-ის გამოყენებით.



პროგნოზი:





TFT მოდელის გამოყენებით გენერირებულია პროგნოზები თითოეული მაღაზია-განყოფილებისთვის.



პროგნოზები შეზღუდულია არაუარყოფით მნიშვნელობებზე.



გაგზავნის ფაილი:





შეიქმნა walmart_submission.csv.



ლოგირებულია WandB-ში.




# 8. PatchTST

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. გაერთიანდა Store და Date-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5 შეივსო 0-ებით, CPI და Unemployment ffill-ით.



კატეგორიული ცვლადები (Store, Dept, Type) გარდაიქმნა LabelEncoder-ის გამოყენებით.



დაემატა სადღესასწაულო თვისებები: SuperBowl, LaborDay, Thanksgiving, Christmas (1 თუ თარიღი ემთხვევა, 0 სხვა შემთხვევაში).



დაემატა დროის თვისებები: Year, Month, Week.



დაემატა Lag_52 (52-კვირიანი lag გაყიდვებისთვის), შევსებული საშუალო მნიშვნელობით.



StandardScaler გამოყენებულია რიცხვით თვისებებზე (Size, Temperature, Fuel_Price, MarkDown1-5, CPI, Unemployment, Year, Month, Week, SuperBowl, LaborDay, Thanksgiving, Christmas, Lag_52) და სამიზნე ცვლადზე (Weekly_Sales).



დროის სერიების შექმნა:





შეიქმნა თანმიმდევრობები seq_length=52 (4 * 13 patches) მაღაზია-განყოფილების წყვილებისთვის.



სასწავლო: 261,083 თანმიმდევრობა (21 თვისება).



ტესტის: 115,064 თანმიმდევრობა.



თვისებები: 18 რიცხვითი (Size, Temperature, Fuel_Price, MarkDown1-5, CPI, Unemployment, Year, Month, Week, SuperBowl, LaborDay, Thanksgiving, Christmas, Lag_52) + 3 კატეგორიული (Store, Dept, Type).

მოდელის არქიტექტურა





PatchTST მოდელი:





Patch Embedding: nn.Linear(patch_length * n_features, d_model) (patch_length=4, n_features=21, d_model=256).



Position Embedding: nn.Parameter (1, n_patches=13, d_model=256).



Transformer: nn.TransformerEncoder n_layers=4, n_heads=8.



Output: nn.Linear(d_model * n_patches, 1) ერთი კვირის პროგნოზისთვის.



პარამეტრები:





seq_length=52, patch_length=4, n_patches=13, d_model=256, n_heads=8, n_layers=4.



Adam ოპტიმიზატორი lr=0.0005, ReduceLROnPlateau (factor=0.5, patience=5).



ზარალი: WMAE (Weighted Mean Absolute Error, წონები: 5 დღესასწაულებზე, 1 სხვა დღეებზე).



ტრენინგი:





30 ეპოქა, batch size=64.



ვალიდაციის გაყოფა: 20% სასწავლო მონაცემებიდან.



WandB მონიტორინგი train_wmae, val_wmae, lr.

შედეგები





საბოლოო მეტრიკები (ეპოქა 30):





Train WMAE: 0.1383



Val WMAE: 0.1665



საუკეთესო Val WMAE: 0.1310 (ეპოქა 13).



Public Score: 5475.74688



ანალიზი:





Val WMAE მერყეობდა (0.1310-0.2197), რაც მიუთითებს არასტაბილურ განზოგადებაზე.



PatchTST-ის მოდელმა გააუმჯობესა DLinear-ის მარტივი მიდგომა (მიდგომა 1: 0.2752 Val WMAE), მაგრამ ჩამორჩა გაძლიერებულ DLinear-ს (მიდგომა 3: 0.0835 Val WMAE).



Transformer-ის არქიტექტურამ (n_heads=8, n_layers=4) შეიძლება გაზარდა სიზუსტე, მაგრამ საჭიროა მეტი ოპტიმიზაცია.



Lag_52 თვისებამ გააუმჯობესა სეზონური ნიმუშების აღქმა, მაგრამ დამატებითი თვისებები (მაგ., სიახლოვის თვისებები) შეიძლება გაუმჯობესდეს.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





იგივე წინასწარი დამუშავება, როგორც სასწავლოზე (სკალირება, lag-52, holiday თვისებები).



თანმიმდევრობები შეიქმნა seq_length=52, შევსებული საშუალო მნიშვნელობებით, თუ ისტორიული მონაცემები არასაკმარისია.



პროგნოზი:





ჩაიტვირთა საუკეთესო მოდელი (best_model.pt, Val WMAE=0.1310).



გენერირებულია პროგნოზები batch-ებით, inverse transform target_scaler-ით.



პროგნოზები შეზღუდულია არაუარყოფით მნიშვნელობებზე.




# 9. N-BEATS


მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, features.csv, stores.csv, test.csv) Google Drive-დან. გაერთიანდა Store, Date და IsHoliday-ზე.



გაწმენდა:





ხარვეზების შევსება: MarkDown1-5 შეივსო 0-ებით, Temperature, Fuel_Price, CPI, Unemployment ffill/bfill-ით ან საშუალო მნიშვნელობებით.



კატეგორიული ცვლადები (Store, Dept, Type) გარდაიქმნა LabelEncoder-ის გამოყენებით, unknown კატეგორიით უცნობი მნიშვნელობებისთვის.



IsHoliday გარდაიქმნა 0/1-ად.



დაემატა დროის თვისებები: Year, Month, Week, DayOfYear, Month_sin, Month_cos, Week_sin, Week_cos.



დაემატა MarkDown1-5_was_missing ინდიკატორები.



დროის სერიების შექმნა:





შეიქმნა თანმიმდევრობები lookback_window=12 მაღაზია-განყოფილების წყვილებისთვის, მინიმუმ 10 ჩანაწერი თითო წყვილზე.



სასწავლო: 297,422 თანმიმდევრობა (12x21 თვისება).



ვალიდაციის: 49,237 თანმიმდევრობა.



თვისებები: Weekly_Sales, IsHoliday, Temperature, Fuel_Price, CPI, Unemployment, Size, MarkDown1-5, MarkDown1-5_was_missing, Month_sin, Month_cos, Week_sin, Week_cos.



სკალირება: StandardScaler თვისებებზე.



მონაცემთა გაყოფა: ვალიდაციის მონაცემები გამოყოფილია ბოლო 20% თარიღებით.

მოდელის არქიტექტურა





N-BEATS მოდელი:





Stack-ები: 2 (trend + seasonality).



Blocks per Stack: 3.



Trend Basis: გამოიყენა TrendBasis (პოლინომიალური გაფართოება).



Seasonality Basis: გამოიყენა SeasonalityBasis (სინუსოიდური ფუნქციები).



Block Structure: nn.Linear (input_size * num_features -> layer_size=512), ReLU, Dropout (0.1), theta_layer (theta_size=32).



გამომავალი: ჯამი ყველა block-ის forecast-ის.



პარამეტრები:





input_size=12, num_features=21, forecast_size=1, stacks=2, blocks_per_stack=3, layers=4, layer_size=512, theta_size=32.



Adam ოპტიმიზატორი lr=1e-4.



ზარალი: WMAE (წონები: 5 დღესასწაულებზე, 1 სხვა დღეებზე).



ტრენინგი:





100 ეპოქა, batch size=64.



WandB მონიტორინგი train_loss, val_loss, val_wmae.

შედეგები





საბოლოო მეტრიკები (ეპოქა 100):





Train Loss: 13764.4344



Val Loss: 13486.2666



Val WMAE: 13490.0205



საუკეთესო Val WMAE: 13331.3350 (ეპოქა 86).



Public Score: არ არის მოწოდებული.



ანალიზი:





Val WMAE მერყეობდა (13331.3350-13852.6846), რაც მიუთითებს განზოგადების გაუმჯობესების პოტენციალზე.



N-BEATS-ის trend და seasonality block-ებმა შეძლეს სეზონური ნიმუშების აღქმა, მაგრამ მაღალი WMAE მიუთითებს შეზღუდვებზე რთულ მაღაზია-განყოფილების ნიმუშებში.



დამატებითი თვისებები (Month_sin/cos, Week_sin/cos) გააუმჯობესა სეზონურობის აღქმა, მაგრამ lag თვისებების არარსებობამ შეიძლება შეამცირა სიზუსტე.

გაგზავნა





ტესტის მონაცემთა დამუშავება:





იგივე წინასწარი დამუშავება, როგორც სასწავლოზე (სკალირება, label encoding, time features).



თანმიმდევრობები მომზადდა lookback_window=12.



პროგნოზი:





ჩაიტვირთა საუკეთესო მოდელი (ეპოქა 86, Val WMAE=13331.3350).



გენერირებულია პროგნოზები batch-ებით.





# 10. Ensemble of tree models 

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, test.csv, features.csv, stores.csv) Google Drive-დან. გაერთიანდა Store და Date-ზე, IsHoliday შენარჩუნდა features.csv-დან.



გაწმენდა:





Date გარდაიქმნა datetime ფორმატში.



MarkDown1-5 ხარვეზები შეივსო 0-ებით.



Temperature, Fuel_Price, CPI, Unemployment ხარვეზები შეივსო საშუალო მნიშვნელობებით.



IsHoliday გარდაიქმნა ორობით (0/1).



ფუნქციების შექმნა:





დაემატა დროის საფუძველზე ფუნქციები: Year, Month, Week, Day, DayOfWeek, Quarter, IsYearEnd, IsYearStart, IsMonthEnd, IsMonthStart.



Store_Dept კომბინაცია, Type კოდირებული LabelEncoder-ით.



Lag ფუნქციები: Weekly_Sales lags (1, 2, 3, 4, 8, 12) და rolling statistics (mean, std) 3, 4, 8 კვირის ფანჯრებით.



მონაცემთა გაყოფა: TimeSeriesSplit (3 split), ბოლო split გამოყენებული ვალიდაციისთვის.

მოდელის არქიტექტურა





მოდელები:





LightGBM: n_estimators=1000, learning_rate=0.05, max_depth=8, num_leaves=31, subsample=0.8, colsample_bytree=0.8.



XGBoost: n_estimators=500, learning_rate=0.05, max_depth=8, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=0.1.



RandomForest: n_estimators=200, max_depth=15, min_samples_split=5, min_samples_leaf=2.



Ensemble: სამივე მოდელის პროგნოზების საშუალო.



ტრენინგი:





თითოეული მოდელი გაწვრთნილია გაყოფილ სასწავლო მონაცემებზე (382955 ჩანაწერი, 36 ფუნქცია).



საბოლოო მოდელები გაწვრთნილია სრულ სასწავლო მონაცემებზე.



შედეგები





საბოლოო მეტრიკები:





LightGBM: Validation WMAE: 1367.9912.



XGBoost: Validation WMAE: 1577.1431.



RandomForest: Validation WMAE: 1378.3604.



Ensemble: Validation WMAE: 1329.0928.



ფუნქციების მნიშვნელობა (LightGBM):





ყველაზე მნიშვნელოვანი: Weekly_Sales_rolling_mean_3 (4657), Weekly_Sales_lag_2 (3796), Weekly_Sales_lag_1 (3768).



ანალიზი:





Ensemble-მა აჩვენა უკეთესი RMSE, ვიდრე XGBoost და RandomForest, მაგრამ MAE ოდნავ უარესი, ვიდრე RandomForest.



Lag და rolling ფუნქციები ყველაზე მნიშვნელოვანია პროგნოზებისთვის.




# 11. Ensemble of deep learning models 

მონაცემთა წინასწარი დამუშავება





მონაცემთა ჩატვირთვა: ჩაიტვირთა Walmart-ის მონაცემები (train.csv, test.csv, features.csv, stores.csv) Google Drive-დან. გაერთიანდა Store და Date-ზე, IsHoliday შენარჩუნდა features.csv-დან.



გაწმენდა:





Date გარდაიქმნა datetime ფორმატში და გადაკეთდა ds-ად NeuralForecast-ისთვის.



MarkDown1-5 ხარვეზები შეივსო 0-ებით.



Temperature, Fuel_Price, CPI, Unemployment ხარვეზები შეივსო საშუალო მნიშვნელობებით (სასწავლო მონაცემებიდან).



IsHoliday გარდაიქმნა ორობით (0/1).



ფუნქციების შექმნა:





შეიქმნა unique_id (Store_Dept კომბინაცია).



დაემატა covariates: Temperature, Fuel_Price, CPI, Unemployment, MarkDown1-5, IsHoliday, Size.



Covariates სტანდარტიზებულია StandardScaler-ით.



ფილტრაცია: გამოირიცხა სერიები <28 (input_size=24 + horizon=4) ჩანაწერით.



მონაცემთა გაყოფა: ვალიდაციისთვის გამოყენებულია ბოლო 4 კვირა თითოეული unique_id-ისთვის.

მოდელის არქიტექტურა





მოდელები:





N-BEATS: input_size=24, horizon=4, max_steps=1000, learning_rate=0.0005, batch_size=8, stack_types=['identity', 'trend', 'seasonality'], n_blocks=[2, 2, 2], mlp_units=[[256, 256], [256, 256], [256, 256]].



TFT: input_size=24, horizon=4, max_steps=1000, learning_rate=0.0005, batch_size=8, hidden_size=32, n_head=4.



PatchTST: input_size=24, horizon=4, max_steps=1000, learning_rate=0.0005, batch_size=8, patch_len=8.



DLinear: input_size=24, horizon=4, max_steps=1000, learning_rate=0.0005, batch_size=8.



Ensemble: ოთხივე მოდელის პროგნოზების საშუალო.



ტრენინგი:





NeuralForecast-ის გამოყენებით, გაწვრთნილია სასწავლო მონაცემებზე (W-FRI სიხშირე).



Early stopping (patience=50), validation check ყოველ 50 ნაბიჯზე.



საბოლოო მოდელები გაწვრთნილია სრულ მონაცემებზე.



შედეგები





საბოლოო მეტრიკები:





N-BEATS: Validation WMAE: 1312.2454.



TFT: Validation WMAE: 1500.8449.



PatchTST: Validation WMAE: 1449.7762.



DLinear: Validation WMAE: 1674.4391.



Ensemble: Validation WMAE: 1426.7006.



ანალიზი:





N-BEATS-მა აჩვენა საუკეთესო WMAE, DLinear-მა ყველაზე ცუდი.



Ensemble-ის MAE უკეთესია, ვიდრე TFT, PatchTST, DLinear, მაგრამ ოდნავ უარესი, ვიდრე N-BEATS.



ხარვეზების შევსებამ და covariates-ის სტანდარტიზაციამ გააუმჯობესა სტაბილურობა.




