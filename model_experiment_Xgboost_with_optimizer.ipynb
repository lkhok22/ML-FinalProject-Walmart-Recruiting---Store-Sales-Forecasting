{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3816,"databundleVersionId":32105,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T18:09:28.959800Z","iopub.execute_input":"2025-07-06T18:09:28.960044Z","iopub.status.idle":"2025-07-06T18:09:31.482593Z","shell.execute_reply.started":"2025-07-06T18:09:28.960023Z","shell.execute_reply":"2025-07-06T18:09:31.481634Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/sampleSubmission.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv\n/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required logging tools\n%pip install -q dagshub \n%pip install -U mlflow\n\n# Initialize DagsHub MLflow integration\nimport dagshub\ndagshub.init(repo_owner='AleksandreBakhtadze', repo_name='ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting', mlflow=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T18:09:31.483660Z","iopub.execute_input":"2025-07-06T18:09:31.484057Z","iopub.status.idle":"2025-07-06T18:10:04.739293Z","shell.execute_reply.started":"2025-07-06T18:09:31.484034Z","shell.execute_reply":"2025-07-06T18:10:04.738159Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting mlflow\n  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\nCollecting mlflow-skinny==3.1.1 (from mlflow)\n  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.1.8)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\nCollecting fastapi<1 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.31.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.31.1)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.4)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.13.2)\nCollecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.1)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.1->mlflow)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (1.2.18)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.1->mlflow)\n  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.52b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.4.26)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\nDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uvicorn, importlib_metadata, gunicorn, graphql-relay, starlette, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib_metadata 8.7.0\n    Uninstalling importlib_metadata-8.7.0:\n      Successfully uninstalled importlib_metadata-8.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed databricks-sdk-0.57.0 fastapi-0.115.14 graphene-3.4.3 graphql-relay-3.2.0 gunicorn-23.0.0 importlib_metadata-8.6.1 mlflow-3.1.1 mlflow-skinny-3.1.1 starlette-0.46.2 uvicorn-0.35.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n\nOpen the following link in your browser to authorize the client:\nhttps://dagshub.com/login/oauth/authorize?state=614c61ad-a568-43d8-91e2-4c29582f1448&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=9a6840e620bb8f960bca50f750ab69ffe81fc72ade8510be88af893cac9100ad\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Accessing as AleksandreBakhtadze\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as AleksandreBakhtadze\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting initialized!\n</pre>\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport zipfile\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nimport mlflow\nimport mlflow.sklearn\nimport joblib\nimport os\nimport optuna\nfrom sklearn.model_selection import TimeSeriesSplit\n\n# Helper functions\ndef read_zipped_csv(path):\n    with zipfile.ZipFile(path) as z:\n        file_name = z.namelist()[0]\n        return pd.read_csv(z.open(file_name))\n\ndef merge_datasets(X, features_df, stores_df):\n    df = X.copy()\n    df_full = df.merge(features_df, on=[\"Store\", \"Date\"], how=\"left\")\n    df_full = df_full.merge(stores_df, on=\"Store\", how=\"left\")\n    df_full = df_full.drop(columns=['IsHoliday_y'], errors='ignore')\n    df_full = df_full.rename(columns={'IsHoliday_x': 'IsHoliday'})\n    return df_full\n\ndef add_markdown_indicators(df):\n    df = df.copy()\n    for i in range(1, 6):\n        df[f'MarkDown{i}_Missing'] = df[f'MarkDown{i}'].isnull().astype(int)\n    return df\n\ndef feature_engineering(df, is_train=True, train_df=None):\n    df = df.copy()\n    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n    df['Year'] = df['Date'].dt.year\n    df['Month'] = df['Date'].dt.month\n    df['Week'] = df['Date'].dt.isocalendar().week.astype(int)\n    df['Day'] = df['Date'].dt.day\n    df['DayOfWeek'] = df['Date'].dt.dayofweek\n    df['Quarter'] = df['Date'].dt.quarter\n    df['IsHoliday'] = df['IsHoliday'].astype(int)\n    df['Type'] = df['Type'].map({'A': 0, 'B': 1, 'C': 2})\n\n    # Holiday proximity features\n    df['DaysToChristmas'] = (pd.to_datetime(df['Year'].astype(str) + '-12-25') - df['Date']).dt.days\n    df['DaysToThanksgiving'] = (pd.to_datetime(df['Year'].astype(str) + '-11-28') - df['Date']).dt.days\n\n    # Interaction features\n    df['Store_Dept'] = df['Store'].astype(str) + '_' + df['Dept'].astype(str)\n\n    if is_train and train_df is not None:\n        # Ensure train_df['Date'] is datetime\n        train_df_sorted = train_df.copy()\n        train_df_sorted['Date'] = pd.to_datetime(train_df_sorted['Date'], format='%Y-%m-%d')\n        train_df_sorted = train_df_sorted.sort_values(['Store', 'Dept', 'Date'])\n        \n        # Create lag and rolling features\n        train_df_sorted['Lag1_Weekly_Sales'] = train_df_sorted.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n        train_df_sorted['Rolling_Mean_7'] = train_df_sorted.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n            lambda x: x.rolling(window=7, min_periods=1).mean()\n        ).shift(1)\n        \n        # Merge lag and rolling features\n        df = df.merge(\n            train_df_sorted[['Store', 'Dept', 'Date', 'Lag1_Weekly_Sales', 'Rolling_Mean_7']],\n            on=['Store', 'Dept', 'Date'],\n            how='left'\n        )\n\n        # Impute missing lag/rolling features\n        df['Lag1_Weekly_Sales'] = df['Lag1_Weekly_Sales'].fillna(df['Lag1_Weekly_Sales'].median())\n        df['Rolling_Mean_7'] = df['Rolling_Mean_7'].fillna(df['Rolling_Mean_7'].median())\n\n    df = add_markdown_indicators(df)\n    return df\n\ndef feature_engineering_train(X):\n    return feature_engineering(X, is_train=True, train_df=train_df)\n\ndef feature_engineering_test(X):\n    return feature_engineering(X, is_train=False, train_df=None)\n\ndef convert_date(df):\n    df = df.copy()\n    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n    return df\n\nclass ForwardFillImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        return X.ffill()\n\nclass DatasetMerger(BaseEstimator, TransformerMixin):\n    def __init__(self, features_df, stores_df):\n        self.features_df = features_df\n        self.stores_df = stores_df\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return merge_datasets(X, self.features_df, self.stores_df)\n\n# Load data\ntrain_df = read_zipped_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip')\nfeatures_df = read_zipped_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip')\nstores_df = pd.read_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv')\ntest_df = read_zipped_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip')\n\n# Convert features_df['Date'] to datetime\nfeatures_df['Date'] = pd.to_datetime(features_df['Date'], format='%Y-%m-%d')\n\n# Ensure train_df['Date'] is datetime\ntrain_df['Date'] = pd.to_datetime(train_df['Date'], format='%Y-%m-%d')\n\n# Feature columns\nfeature_cols = [\n    'Store', 'Dept', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n    'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5',\n    'MarkDown1_Missing', 'MarkDown2_Missing', 'MarkDown3_Missing', 'MarkDown4_Missing', 'MarkDown5_Missing',\n    'IsHoliday', 'Year', 'Month', 'Week', 'DayOfWeek', 'Quarter',\n    'DaysToChristmas', 'DaysToThanksgiving', 'Store_Dept', 'Lag1_Weekly_Sales', 'Rolling_Mean_7'\n]\n\n# Preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num_ffill', ForwardFillImputer(), ['CPI', 'Unemployment']),\n        ('markdown_fill', SimpleImputer(strategy='median'), \n         ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']),\n        ('scale', StandardScaler(), ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size', \n                                    'DaysToChristmas', 'DaysToThanksgiving', 'Lag1_Weekly_Sales', 'Rolling_Mean_7']),\n        ('passthrough', 'passthrough', \n         ['Store', 'Dept', 'Type', 'IsHoliday', 'Year', 'Month', 'Week', 'DayOfWeek', 'Quarter',\n          'MarkDown1_Missing', 'MarkDown2_Missing', 'MarkDown3_Missing', 'MarkDown4_Missing', 'MarkDown5_Missing',\n          'Store_Dept'])\n    ]\n)\n\n# WMAE metric\ndef calculate_wmae(y_true, y_pred, is_holiday):\n    weights = np.where(is_holiday, 5, 1)\n    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n\n# Hyperparameter tuning with Optuna\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 500),  # Expanded range\n        'max_depth': trial.suggest_int('max_depth', 3, 12),  # Deeper trees\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.5, log=True),  # Wider range\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),  # Expanded range\n        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),  # L1 regularization\n        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)  # L2 regularization\n    }\n    \n    pipeline = Pipeline([\n        ('convert_date', FunctionTransformer(convert_date, validate=False)),\n        ('merge', DatasetMerger(features_df=features_df, stores_df=stores_df)),\n        ('feature_engineering', FunctionTransformer(feature_engineering_train, validate=False)),\n        ('preprocess', preprocessor),\n        ('model', XGBRegressor(**params, random_state=42, n_jobs=-1))\n    ])\n    \n    tscv = TimeSeriesSplit(n_splits=3)\n    wmae_scores = []\n    \n    for train_idx, val_idx in tscv.split(X_train):\n        X_t, y_t = X_train.iloc[train_idx], y_train.iloc[train_idx]\n        X_v, y_v = X_train.iloc[val_idx], y_train.iloc[val_idx]\n        is_holiday_v = X_v['IsHoliday']\n        \n        pipeline.fit(X_t, y_t)\n        y_pred = pipeline.predict(X_v)\n        wmae = calculate_wmae(y_v, y_pred, is_holiday_v)\n        wmae_scores.append(wmae)\n    \n    return np.mean(wmae_scores)\n\n# Prepare training data\ntrain_full = train_df.copy()\ny = train_full['Weekly_Sales']\ntrain_full = train_full.drop(columns=['Weekly_Sales'])\ntrain_full['Date'] = pd.to_datetime(train_full['Date'], format='%Y-%m-%d')\n\n# Split data\ntrain_full = train_full.sort_values('Date')\nsplit_date = train_full['Date'].quantile(0.9)\ntrain_idx = train_full['Date'] < split_date\nX_train = train_full[train_idx]\ny_train = np.clip(y[train_idx], 0, y.quantile(0.99))\nX_val = train_full[~train_idx]\ny_val = y[~train_idx]\nis_holiday_val = X_val['IsHoliday']\n\n# Optimize hyperparameters\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)  # Increased trials for better search\n\n# Best parameters\nbest_params = study.best_params\nprint(\"Best parameters:\", best_params)\n\n# Final pipeline with best parameters\npipeline = Pipeline([\n    ('convert_date', FunctionTransformer(convert_date, validate=False)),\n    ('merge', DatasetMerger(features_df=features_df, stores_df=stores_df)),\n    ('feature_engineering', FunctionTransformer(feature_engineering_train, validate=False)),\n    ('preprocess', preprocessor),\n    ('model', XGBRegressor(**best_params, random_state=42, n_jobs=-1))\n])\n\n# MLflow setup\nos.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting.mlflow'\nos.environ['MLFLOW_TRACKING_USERNAME'] = 'AleksandreBakhtadze'\nos.environ['MLFLOW_TRACKING_PASSWORD'] = '034b77b38fbceb0a45865e04299f524469d930d4'\n\nmlflow.set_experiment(\"XGBoost_Improved_Pipeline\")\n\n# End any active MLflow run\nmlflow.end_run()\n\nwith mlflow.start_run(run_name=\"XGBoost_Optimized\"):\n    # Fit pipeline\n    pipeline.fit(X_train, y_train)\n    \n    # Predict and evaluate\n    y_pred = pipeline.predict(X_val)\n    mae = mean_absolute_error(y_val, y_pred)\n    wmae = calculate_wmae(y_val, y_pred, is_holiday_val)\n    print(f\"Validation MAE: {mae:.2f}\")\n    print(f\"Validation WMAE: {wmae:.2f}\")\n    \n    # Log parameters and metrics\n    for param, value in best_params.items():\n        mlflow.log_param(param, value)\n    mlflow.log_param(\"random_state\", 42)\n    mlflow.log_metric(\"val_mae\", mae)\n    mlflow.log_metric(\"val_wmae\", wmae)\n    \n    # Save model as artifact (skip registration due to endpoint error)\n    os.makedirs(\"/kaggle/working/models\", exist_ok=True)\n    model_path = \"/kaggle/working/models/xgboost_optimized.joblib\"\n    joblib.dump(pipeline, model_path)\n    mlflow.log_artifact(model_path)\n    print(f\"Model saved as artifact: {model_path}\")\n\n# Test predictions with modified feature engineering for test set\ntest_full = test_df.copy()\npipeline.named_steps['feature_engineering'] = FunctionTransformer(feature_engineering_test, validate=False)\ntest_preds = pipeline.predict(test_full)\n\n# Submission\ntest_full_transformed = pipeline.named_steps['convert_date'].transform(test_full)\ntest_full_transformed = pipeline.named_steps['merge'].transform(test_full_transformed)\ntest_full_transformed = pipeline.named_steps['feature_engineering'].transform(test_full_transformed)\ntest_full_transformed['Id'] = test_full_transformed['Store'].astype(str) + '_' + test_full_transformed['Dept'].astype(str) + '_' + test_full_transformed['Date'].dt.strftime('%Y-%m-%d')\nsubmission_df = pd.DataFrame({'Id': test_full_transformed['Id'], 'Weekly_Sales': test_preds})\nsubmission_df.to_csv(\"submission.csv\", index=False)\nmlflow.log_artifact(\"submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T18:19:56.690962Z","iopub.execute_input":"2025-07-06T18:19:56.691316Z","iopub.status.idle":"2025-07-06T18:38:04.401614Z","shell.execute_reply.started":"2025-07-06T18:19:56.691292Z","shell.execute_reply":"2025-07-06T18:38:04.400571Z"}},"outputs":[{"name":"stderr","text":"[I 2025-07-06 18:19:57,226] A new study created in memory with name: no-name-3bd13cb3-ceee-4e4a-9d58-5f0b8958b400\n[I 2025-07-06 18:20:30,864] Trial 0 finished with value: 15858.626930233222 and parameters: {'n_estimators': 252, 'max_depth': 11, 'learning_rate': 0.04329351674961105, 'subsample': 0.6831684776872025, 'colsample_bytree': 0.7752516137814925, 'min_child_weight': 13, 'reg_alpha': 0.8619552349619864, 'reg_lambda': 0.06662380736081364}. Best is trial 0 with value: 15858.626930233222.\n[I 2025-07-06 18:21:24,933] Trial 1 finished with value: 26011.873001592478 and parameters: {'n_estimators': 461, 'max_depth': 10, 'learning_rate': 0.4264227009977883, 'subsample': 0.5097233193840252, 'colsample_bytree': 0.9520237560868337, 'min_child_weight': 7, 'reg_alpha': 0.3080627279135333, 'reg_lambda': 0.7928366018646736}. Best is trial 0 with value: 15858.626930233222.\n[I 2025-07-06 18:21:48,635] Trial 2 finished with value: 14850.876089265335 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.013611639118154249, 'subsample': 0.8118866649601264, 'colsample_bytree': 0.7838693866151389, 'min_child_weight': 7, 'reg_alpha': 0.30390173306631973, 'reg_lambda': 0.7339698926231304}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:22:05,372] Trial 3 finished with value: 14883.556014063812 and parameters: {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.02275264666759819, 'subsample': 0.6623456638026892, 'colsample_bytree': 0.8965944436314617, 'min_child_weight': 11, 'reg_alpha': 0.7950774113715792, 'reg_lambda': 0.9593685084980564}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:22:49,662] Trial 4 finished with value: 16117.297126998623 and parameters: {'n_estimators': 435, 'max_depth': 11, 'learning_rate': 0.0668438808865516, 'subsample': 0.998309056853824, 'colsample_bytree': 0.5542376361555471, 'min_child_weight': 9, 'reg_alpha': 0.6995314633977144, 'reg_lambda': 0.014743983236319536}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:23:19,702] Trial 5 finished with value: 15507.038425318155 and parameters: {'n_estimators': 466, 'max_depth': 7, 'learning_rate': 0.01745407581953192, 'subsample': 0.783605574593579, 'colsample_bytree': 0.7409728027925647, 'min_child_weight': 1, 'reg_alpha': 0.005870353922715177, 'reg_lambda': 0.5349504933773419}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:23:38,363] Trial 6 finished with value: 16598.928108412278 and parameters: {'n_estimators': 391, 'max_depth': 3, 'learning_rate': 0.05440840371678334, 'subsample': 0.5245690967951981, 'colsample_bytree': 0.7383788594836145, 'min_child_weight': 9, 'reg_alpha': 0.6352404848942723, 'reg_lambda': 0.9458554064276128}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:24:21,766] Trial 7 finished with value: 20702.354548803425 and parameters: {'n_estimators': 477, 'max_depth': 9, 'learning_rate': 0.39059362075006215, 'subsample': 0.9693685271135347, 'colsample_bytree': 0.7850668285902695, 'min_child_weight': 1, 'reg_alpha': 0.7560954246443884, 'reg_lambda': 0.6620867409838825}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:24:42,310] Trial 8 finished with value: 17148.491384275472 and parameters: {'n_estimators': 409, 'max_depth': 4, 'learning_rate': 0.10850502323153378, 'subsample': 0.8957895442278663, 'colsample_bytree': 0.5011862162629406, 'min_child_weight': 15, 'reg_alpha': 0.9037375146878335, 'reg_lambda': 0.3938390872365348}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:25:06,837] Trial 9 finished with value: 15297.583877013909 and parameters: {'n_estimators': 443, 'max_depth': 4, 'learning_rate': 0.012153360509109522, 'subsample': 0.6285864668938277, 'colsample_bytree': 0.9435031901192541, 'min_child_weight': 7, 'reg_alpha': 0.6357756112305851, 'reg_lambda': 0.9061902772906149}. Best is trial 2 with value: 14850.876089265335.\n[I 2025-07-06 18:25:34,687] Trial 10 finished with value: 14611.220099070517 and parameters: {'n_estimators': 99, 'max_depth': 12, 'learning_rate': 0.005918503608264826, 'subsample': 0.8191804694468511, 'colsample_bytree': 0.6706498839012336, 'min_child_weight': 4, 'reg_alpha': 0.33064784504134337, 'reg_lambda': 0.30698157604122417}. Best is trial 10 with value: 14611.220099070517.\n[I 2025-07-06 18:25:56,429] Trial 11 finished with value: 14601.43644161985 and parameters: {'n_estimators': 61, 'max_depth': 12, 'learning_rate': 0.005199987572596572, 'subsample': 0.8217739021031092, 'colsample_bytree': 0.6902010439469567, 'min_child_weight': 4, 'reg_alpha': 0.3269455148130603, 'reg_lambda': 0.28005318104249477}. Best is trial 11 with value: 14601.43644161985.\n[I 2025-07-06 18:26:18,920] Trial 12 finished with value: 14592.246559812922 and parameters: {'n_estimators': 63, 'max_depth': 12, 'learning_rate': 0.005067191532563109, 'subsample': 0.8619989649650852, 'colsample_bytree': 0.6368653135147855, 'min_child_weight': 4, 'reg_alpha': 0.35430872748966624, 'reg_lambda': 0.28031048138466913}. Best is trial 12 with value: 14592.246559812922.\n[I 2025-07-06 18:27:05,682] Trial 13 finished with value: 14755.860224951122 and parameters: {'n_estimators': 201, 'max_depth': 12, 'learning_rate': 0.0054907893954670595, 'subsample': 0.8951500319886379, 'colsample_bytree': 0.6113759843542839, 'min_child_weight': 4, 'reg_alpha': 0.45698323815103437, 'reg_lambda': 0.19820301444584298}. Best is trial 12 with value: 14592.246559812922.\n[I 2025-07-06 18:27:20,415] Trial 14 finished with value: 14547.60010742652 and parameters: {'n_estimators': 56, 'max_depth': 8, 'learning_rate': 0.007888490440512829, 'subsample': 0.8841894478930764, 'colsample_bytree': 0.6578331485690733, 'min_child_weight': 4, 'reg_alpha': 0.17754173801981593, 'reg_lambda': 0.20789699221745883}. Best is trial 14 with value: 14547.60010742652.\n[I 2025-07-06 18:27:49,881] Trial 15 finished with value: 14812.936598773493 and parameters: {'n_estimators': 328, 'max_depth': 8, 'learning_rate': 0.008302697792907753, 'subsample': 0.9009561495056837, 'colsample_bytree': 0.6238888386798301, 'min_child_weight': 3, 'reg_alpha': 0.07392124759573868, 'reg_lambda': 0.15660290626576612}. Best is trial 14 with value: 14547.60010742652.\n[I 2025-07-06 18:28:09,984] Trial 16 finished with value: 15029.666526517363 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.025304293363394226, 'subsample': 0.7413012152614707, 'colsample_bytree': 0.6152137749091151, 'min_child_weight': 5, 'reg_alpha': 0.1382304218365401, 'reg_lambda': 0.4802264415728062}. Best is trial 14 with value: 14547.60010742652.\n[I 2025-07-06 18:28:23,584] Trial 17 finished with value: 14477.143745764588 and parameters: {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.010558594508774749, 'subsample': 0.9368769091423239, 'colsample_bytree': 0.8746968410442786, 'min_child_weight': 2, 'reg_alpha': 0.18504540374831363, 'reg_lambda': 0.16537426759935459}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:28:42,438] Trial 18 finished with value: 14573.407616995368 and parameters: {'n_estimators': 179, 'max_depth': 6, 'learning_rate': 0.010734433448259096, 'subsample': 0.9529496245166587, 'colsample_bytree': 0.8607617724830944, 'min_child_weight': 2, 'reg_alpha': 0.18819605399147873, 'reg_lambda': 0.10796978465129967}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:29:02,848] Trial 19 finished with value: 17559.720588932178 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.1787114422431838, 'subsample': 0.9442948035324136, 'colsample_bytree': 0.8410191248099623, 'min_child_weight': 6, 'reg_alpha': 0.49366340497558714, 'reg_lambda': 0.41113061020533037}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:29:18,976] Trial 20 finished with value: 14680.817910090967 and parameters: {'n_estimators': 53, 'max_depth': 8, 'learning_rate': 0.02902267211377052, 'subsample': 0.7464763346343802, 'colsample_bytree': 0.843916754468024, 'min_child_weight': 2, 'reg_alpha': 0.15431197245811584, 'reg_lambda': 0.206393645737274}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:29:35,965] Trial 21 finished with value: 14565.739125154958 and parameters: {'n_estimators': 168, 'max_depth': 6, 'learning_rate': 0.010084901600552011, 'subsample': 0.9404777836176391, 'colsample_bytree': 0.8645708148299964, 'min_child_weight': 2, 'reg_alpha': 0.20730151431060995, 'reg_lambda': 0.11141559735608826}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:29:50,936] Trial 22 finished with value: 14539.15759998193 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.00825917918426198, 'subsample': 0.9307277594339202, 'colsample_bytree': 0.9959308263853288, 'min_child_weight': 2, 'reg_alpha': 0.21781113747576222, 'reg_lambda': 0.0634542818065725}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:30:06,089] Trial 23 finished with value: 14518.203541326739 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.007989492922640683, 'subsample': 0.8546784700058091, 'colsample_bytree': 0.9930332462311655, 'min_child_weight': 1, 'reg_alpha': 0.02493639501531339, 'reg_lambda': 0.0531927973989115}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:30:22,139] Trial 24 finished with value: 14610.203815727024 and parameters: {'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.017769410255292377, 'subsample': 0.8513705430188688, 'colsample_bytree': 0.9884404586962058, 'min_child_weight': 1, 'reg_alpha': 0.00326995420129092, 'reg_lambda': 0.043080893818797636}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:30:36,979] Trial 25 finished with value: 14924.309174061449 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.03409384476843471, 'subsample': 0.9883165689080762, 'colsample_bytree': 0.9967522560682628, 'min_child_weight': 3, 'reg_alpha': 0.1158048829594454, 'reg_lambda': 0.005010504940876896}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:30:52,888] Trial 26 finished with value: 14890.662671938708 and parameters: {'n_estimators': 229, 'max_depth': 3, 'learning_rate': 0.016809873732525293, 'subsample': 0.9294611435461255, 'colsample_bytree': 0.9263425687611159, 'min_child_weight': 2, 'reg_alpha': 0.24478181662965137, 'reg_lambda': 0.12562732505546076}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:31:08,591] Trial 27 finished with value: 14555.802423530657 and parameters: {'n_estimators': 153, 'max_depth': 5, 'learning_rate': 0.006983124558297925, 'subsample': 0.8611241557215474, 'colsample_bytree': 0.9110382268134469, 'min_child_weight': 5, 'reg_alpha': 0.41232009369050004, 'reg_lambda': 0.27532545554070376}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:31:22,239] Trial 28 finished with value: 14675.843024740525 and parameters: {'n_estimators': 88, 'max_depth': 4, 'learning_rate': 0.0090210200696755, 'subsample': 0.914698615663201, 'colsample_bytree': 0.9658728355156787, 'min_child_weight': 1, 'reg_alpha': 0.06956654450643432, 'reg_lambda': 0.36111708329711245}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:31:40,627] Trial 29 finished with value: 14816.18975779319 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.013390470111137176, 'subsample': 0.7912993387801077, 'colsample_bytree': 0.8908741237221867, 'min_child_weight': 12, 'reg_alpha': 0.2330614715729187, 'reg_lambda': 0.07239094835376861}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:32:07,414] Trial 30 finished with value: 16185.704041825971 and parameters: {'n_estimators': 332, 'max_depth': 7, 'learning_rate': 0.03890121990210489, 'subsample': 0.7103889812863047, 'colsample_bytree': 0.9727532385329776, 'min_child_weight': 3, 'reg_alpha': 0.050335559719363876, 'reg_lambda': 0.172134355782401}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:32:25,439] Trial 31 finished with value: 14551.989990129667 and parameters: {'n_estimators': 88, 'max_depth': 8, 'learning_rate': 0.007763008627679138, 'subsample': 0.8736772394941008, 'colsample_bytree': 0.809041398184003, 'min_child_weight': 3, 'reg_alpha': 0.9882410808013233, 'reg_lambda': 0.21943647602579835}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:32:41,117] Trial 32 finished with value: 14551.504015972563 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.007557613433276637, 'subsample': 0.8446576748295743, 'colsample_bytree': 0.95146098643554, 'min_child_weight': 5, 'reg_alpha': 0.12305417068235358, 'reg_lambda': 0.1151682969059352}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:32:57,407] Trial 33 finished with value: 14563.93569414137 and parameters: {'n_estimators': 116, 'max_depth': 6, 'learning_rate': 0.014279404848934205, 'subsample': 0.9641837928704088, 'colsample_bytree': 0.7041356344082054, 'min_child_weight': 2, 'reg_alpha': 0.24548984967655896, 'reg_lambda': 0.06055892392626037}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:33:14,906] Trial 34 finished with value: 14801.991230864203 and parameters: {'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.020009371971655077, 'subsample': 0.9253132204641813, 'colsample_bytree': 0.9212109363601267, 'min_child_weight': 1, 'reg_alpha': 0.3922345203848768, 'reg_lambda': 0.24205254270045132}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:33:36,325] Trial 35 finished with value: 14677.8248821906 and parameters: {'n_estimators': 112, 'max_depth': 9, 'learning_rate': 0.010904918397314944, 'subsample': 0.7750179539706002, 'colsample_bytree': 0.9986285585707643, 'min_child_weight': 6, 'reg_alpha': 0.27761732332904243, 'reg_lambda': 0.6028152371839822}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:33:49,524] Trial 36 finished with value: 14628.118797835887 and parameters: {'n_estimators': 78, 'max_depth': 4, 'learning_rate': 0.006949029939964883, 'subsample': 0.8803162359641739, 'colsample_bytree': 0.8126451203311764, 'min_child_weight': 8, 'reg_alpha': 0.16632832567059555, 'reg_lambda': 0.0035691629619376136}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:34:07,331] Trial 37 finished with value: 14648.795787002942 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.01446240744620674, 'subsample': 0.9947177377057439, 'colsample_bytree': 0.8781355688543041, 'min_child_weight': 3, 'reg_alpha': 0.05882791556364693, 'reg_lambda': 0.06618641255958924}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:34:37,231] Trial 38 finished with value: 16808.737874747894 and parameters: {'n_estimators': 211, 'max_depth': 10, 'learning_rate': 0.09377839704526655, 'subsample': 0.8325512894537234, 'colsample_bytree': 0.581050189672011, 'min_child_weight': 2, 'reg_alpha': 0.5731867735805072, 'reg_lambda': 0.15918438089408482}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:34:52,111] Trial 39 finished with value: 14592.380748653137 and parameters: {'n_estimators': 74, 'max_depth': 7, 'learning_rate': 0.025148720071224023, 'subsample': 0.9689810033841436, 'colsample_bytree': 0.7716094954939308, 'min_child_weight': 10, 'reg_alpha': 0.10114878670831284, 'reg_lambda': 0.34697451325793527}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:35:06,364] Trial 40 finished with value: 15389.328787722283 and parameters: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.05492787221327354, 'subsample': 0.6046239168554601, 'colsample_bytree': 0.9537798357009075, 'min_child_weight': 14, 'reg_alpha': 0.27764448436453715, 'reg_lambda': 0.7858351318482918}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:35:21,744] Trial 41 finished with value: 14557.527916586181 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.006965927556577213, 'subsample': 0.8438695528558172, 'colsample_bytree': 0.9396687633283226, 'min_child_weight': 5, 'reg_alpha': 0.16773882433568216, 'reg_lambda': 0.11111949549311537}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:35:43,665] Trial 42 finished with value: 14621.90495006155 and parameters: {'n_estimators': 97, 'max_depth': 10, 'learning_rate': 0.00922670609502635, 'subsample': 0.9109389604271473, 'colsample_bytree': 0.9686173272839944, 'min_child_weight': 6, 'reg_alpha': 6.266758316733623e-05, 'reg_lambda': 0.0699195247763165}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:35:59,127] Trial 43 finished with value: 14621.493642800679 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.006384558876185451, 'subsample': 0.8793888106602609, 'colsample_bytree': 0.9378542044437524, 'min_child_weight': 1, 'reg_alpha': 0.11504956861105928, 'reg_lambda': 0.162958843765414}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:36:16,939] Trial 44 finished with value: 14600.808634643865 and parameters: {'n_estimators': 112, 'max_depth': 8, 'learning_rate': 0.01167256121815117, 'subsample': 0.7990259764861182, 'colsample_bytree': 0.9020928195705219, 'min_child_weight': 4, 'reg_alpha': 0.04568596526625493, 'reg_lambda': 0.22871790829869}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:36:35,800] Trial 45 finished with value: 14577.343923371367 and parameters: {'n_estimators': 74, 'max_depth': 10, 'learning_rate': 0.008722045727952725, 'subsample': 0.8342691805512287, 'colsample_bytree': 0.9776267302721945, 'min_child_weight': 5, 'reg_alpha': 0.20430205484266914, 'reg_lambda': 0.4642314497011245}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:36:53,644] Trial 46 finished with value: 17973.129804159966 and parameters: {'n_estimators': 69, 'max_depth': 11, 'learning_rate': 0.3285428898490345, 'subsample': 0.7697170319804464, 'colsample_bytree': 0.7166366433683782, 'min_child_weight': 8, 'reg_alpha': 0.2988312593238967, 'reg_lambda': 0.1404449368991492}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:37:09,572] Trial 47 finished with value: 14485.31753039804 and parameters: {'n_estimators': 107, 'max_depth': 7, 'learning_rate': 0.006021104817690278, 'subsample': 0.8990759379533004, 'colsample_bytree': 0.6551573206466719, 'min_child_weight': 4, 'reg_alpha': 0.36469763298218916, 'reg_lambda': 0.08582221568720211}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:37:27,302] Trial 48 finished with value: 14510.70320069955 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.005739382415078237, 'subsample': 0.886312238157688, 'colsample_bytree': 0.6558631906614077, 'min_child_weight': 3, 'reg_alpha': 0.37053707105298234, 'reg_lambda': 0.03228729587321366}. Best is trial 17 with value: 14477.143745764588.\n[I 2025-07-06 18:37:45,917] Trial 49 finished with value: 14551.978612694285 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.005165425825814823, 'subsample': 0.9197382871039247, 'colsample_bytree': 0.5333591492046397, 'min_child_weight': 1, 'reg_alpha': 0.37084277603701354, 'reg_lambda': 0.03731801313454005}. Best is trial 17 with value: 14477.143745764588.\n","output_type":"stream"},{"name":"stdout","text":"Best parameters: {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.010558594508774749, 'subsample': 0.9368769091423239, 'colsample_bytree': 0.8746968410442786, 'min_child_weight': 2, 'reg_alpha': 0.18504540374831363, 'reg_lambda': 0.16537426759935459}\nValidation MAE: 14431.84\nValidation WMAE: 14150.16\nModel saved as artifact: /kaggle/working/models/xgboost_optimized.joblib\n🏃 View run XGBoost_Optimized at: https://dagshub.com/AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/4/runs/4bff9df295f94ac29899c469ed8f47e2\n🧪 View experiment at: https://dagshub.com/AleksandreBakhtadze/ML-FinalProject-Walmart-Recruiting---Store-Sales-Forecasting.mlflow/#/experiments/4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
